\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[a4paper]{geometry}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{adjustbox}
\usepackage[shortlabels]{enumitem}
\usepackage{parskip}
\makeatletter
\newcommand{\@minipagerestore}{\setlength{\parskip}{\medskipamount}}
\makeatother
\usepackage{imakeidx}

\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{null}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\Orb}{Orb}
\DeclareMathOperator{\Stab}{Stab}
\DeclareMathOperator{\ccl}{ccl}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Syl}{Syl}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Fit}{Fit}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\erf}{erf}


\newcommand{\incfig}[1]{%
	\def\svgwidth{\columnwidth}
	\import{./figures/}{#1.pdf_tex}
}
\newcommand{\diff}{\mathop{}\!\mathrm{d}}
\newcommand{\Diff}[1]{\mathop{}\!\mathrm{d}^{#1}}

\setlength\parindent{0pt}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\pagestyle{fancy}
\fancyhf{}
\rhead{\leftmark}
\lhead{Page \thepage}
\setlength{\headheight}{15pt}

\makeindex[intoc]

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newcommand{\mapsfrom}{\mathrel{\reflectbox{\ensuremath{\mapsto}}}}

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{IB Methods}

		\vspace{1em}
		\large
		Ishan Nath, Michaelmas 2022

		\vspace{1.5em}

		\Large

		Based on Lectures by Prof. Edward Shellard

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

\part{Self-Adjoint ODE'S}%
\label{prt:self_adjoint_ode_s}

\section{Fourier Series}%
\label{sec:fourier_series}

\subsection{Periodic Functions}%
\label{sub:periodic_functions}

A function $f(x)$ is \textbf{periodic}\index{periodic function} if
\[
	f(x + T) = f(x)
,\]
where $T$ is the period.

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\begin{example} Consider simple harmonic motion. We have
\[
y = A \sin \omega t
,\]
where $A$ is the amplitude and the period $T = 2 \pi / \omega$, with angular frequency $\omega$.
\end{example}
\end{adjustbox}

Consider the set of functions
\[
	g_n(x) = \cos \frac{n \pi x}{L}, \quad h_n(x) = \sin \frac{n \pi x}{L}
,\]
which are periodic on the interval $0 \leq x < 2L$. Recall the identities
\begin{align*}
	\cos A \cos B &= \frac{1}{2} \left(\cos(A - B) + \cos (A + B) \right), \\
	\sin A \sin B &= \frac{1}{2} \left( \cos(A - B) - \cos(A + B) \right), \\
	\sin A \cos B &=  \frac{1}{2} \left( \sin(A - B) + \sin(A + B) \right).
\end{align*}

Define the \textbf{inner product}\index{inner product of periodic functions} for two periodic functions $f, g$ on the interval $[0, 2L)$ 
\[
	\langle f, g \rangle = \int_{0}^{2L}f(x) g(x)\diff x
.\]
I claim that the functions $g_n, h_m$ are \textbf{mutually orthogonal}. Indeed,
\begin{align*}
	\langle h_n, h_m \rangle &= \int_{0}^{2L} \sin \frac{n \pi x}{L} \sin \frac{m \pi x}{L}\diff x \\
				 &= \frac{1}{2} \int_{0}^{2L} \left( \cos \frac{(n - m)\pi x}{L} - \cos \frac{(n + m)\pi x}{L}\right)\diff x \\
				 &= \frac{1}{2} \frac{L}{\pi} \left[ \frac{\sin (n - m) \pi x/L}{n - m} - \frac{\sin (n + m) \pi x/L}{n + m} \right]_{0}^{2L} = 0.
\end{align*}
This works for $n \neq m$. For $n = m$,
\begin{align*}
	\langle h_n, h_n \rangle &= \int_{0}^{2L} \sin^2 \frac{n \pi x}{L}\diff x \\
				 &= \frac{1}{2} \int_{0}^{2L} \left( 1 - \cos \frac{2 \pi n x}{L} \right)\diff x \\
				 &= L \;\; (n \neq 0).
\end{align*}
Hence, we can put these together to get
\[
	\langle h_n, h_m \rangle =
	\begin{cases}
		L \delta_{nm}, & \forall\,\! n, m \neq 0, \\
		0, & n = 0.
	\end{cases}
\] 
Similarly, we can show
\[
	\langle g_n, g_m \rangle =
	\begin{cases}
		L \delta_{nm}, & \forall\,\! n, m \neq 0, \\
		2L \delta_{0n}, &m = 0.
	\end{cases}
	\quad \text{ and } \; \langle h_n, g_m \rangle = 0
.\]

\subsection{Definition of Fourier series}%
\label{sub:definition_of_fourier_series}\index{Fourier series}

We can express any `well-behaved' periodic function $f(x)$ with period $2L$ as
\[
	f(x) = \frac{1}{2}a_0  + \sum_{n = 1}^{\infty} a_n \cos \frac{n \pi x}{L} + \sum_{n = 1}^{\infty}b_n \sin \frac{n \pi x}{L}
,\]

where $a_n, b_n$ are constant such that the right hand side is convergent for all $x$ where $f$ is continuous. At a discontinuity $x$, the Fourier series approaches the midpoint
\[
	\frac{1}{2} \left( f(x_{+}) + f(x_{-}) \right)
.\]
\subsubsection{Fourier Coefficients}%
\label{subsub:fourier_coefficients}\index{Fourier coefficients}

Consider the inner product
\[
	\langle h_m(x), f(x) \rangle = \int_{0}^{2L} \sin \frac{m \pi x}{L} f(x)\diff x = L b_m
,\]
by the orthogonality relations. Hence we find that
\begin{align*}
	b_n &= \frac{1}{L} \int_{0}^{2L}f(x) \sin \frac{n \pi x}{L}\diff x, \\
	a_n &= \frac{1}{L} \int_{0}^{2L}f(x) \cos \frac{n \pi x}{L}\diff x.
\end{align*}
\begin{remark}
	\begin{enumerate}[(i)]
		\item[]
		\item $a_n$ includes $n = 0$, since $\frac{1}{2} a_0$ is the \textbf{average}
			\[
				\langle f(x) \rangle = \frac{1}{2L} \int_{0}^{2L} f(x)\diff x
			.\]
		\item The range of integration is over one period, so we may take the integral over $[0, 2L)$ or $[-L, L)$.
		\item We can think of the Fourier series as a decomposition into harmonics. The simplest Fourier series are the sine and cosine functions.
	\end{enumerate}	
\end{remark}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\begin{example}[Sawtooth wave]\index{sawtooth wave}
\item
	Consider the function $f(x) = x$ for $-L \leq x < L$, periodic with period $T = 2L$. The cosine coefficients are
	\[
	a_n = \frac{1}{L} \int_{-L}^{L} x \cos \frac{n \pi x}{L}\diff x = 0
	,\]
	as $x \cos \omega x$ is odd. The sine coefficients are
	\begin{align*}
		b_n &= \frac{2}{L} \int_{0}^{L} x \sin \frac{n \pi x}{L}\diff x \\
		    &= -\frac{2}{n \pi} \left[ x \cos \frac{n \pi x}{L} \right]_{0}^{L} + \frac{2}{n \pi} \int_{0}^{L} \cos \frac{n \pi x}{L}\diff x \\
		    &= - \frac{2L}{n \pi} \cos n \pi + \frac{2L}{(n \pi)^2} \sin n \pi = \frac{2L}{n \pi }(-1)^{n+1}.
	\end{align*}
	
\end{example}

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	So the sawtooth Fourier series is
	\begin{align*}
		f(x) &= \frac{2L}{\pi} \sum_{n = 1}^{\infty} \frac{(-1)^{n+1}}{n} \sin \frac{n \pi x}{L} \\
		     &= \frac{2L}{\pi} \left( \sin \frac{\pi x}{L} - \frac{1}{2} \sin \frac{2 \pi x}{L} + \frac{1}{3} \sin \frac{3 \pi x}{L} - \cdots \right).
	\end{align*}

\end{adjustbox}

With Fourier series, we can construct functions with only finitely many discontinuities, the topologist's sine curve, and the Weierstrass function.

\subsection{The Dirichlet Conditions (Fourier's theorem)}%
\label{sub:the_dirichlet_conditions_fourier_s_theorem_}\index{Dirichlet conditions}

These are sufficiency conditions for a ``well-behaved'' function to have a unique Fourier series:

\begin{proposition}
	If $f(x)$ is a bounded periodic function (period $2L$) with a finite number of minima, maxima and discontinuities in $0 \leq x < 2L$, then the Fourier series converges to  $f(x)$ at all points where $f$ is continuous; at discontinuities the series converges to the midpoint.
\end{proposition}

\begin{remark}
	\begin{enumerate}[(i)]
		\item[]
		\item These are weak conditions (in contrast to Taylor series), but pathological functions are excluded, such as
			\[
				f(x) = \frac{1}{x}, \quad f(x) = \sin \frac{1}{x}, \quad f(x) =
				\begin{cases}
					0 & x \in \mathbb{Q},\\
					1 & x \not \in \mathbb{Q}.
				\end{cases}
			\]
		\item The converse is not true.
		\item The proof is difficult.
	\end{enumerate}
	
\end{remark}

\subsubsection{Convergence of Fourier Series}%
\label{subsub:convergence_of_fourier_series}

\begin{theorem}
	If $f(x)$ has continuous derivatives up to the $p$'th derivative, which is discontinuous, then the Fourier series converges as $\mathcal{O}(n^{-(p+1)})$.
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Take the square wave\index{square wave}, with $p = 0$.
	\[
		f(x) =
		\begin{cases}
			1 & 0 \leq x < 1, \\
			-1 & -1 \leq x < 0.
		\end{cases}
	\]
	The Fourier series is
	\[
		f(x) = 4 \sum_{m = 1}^{\infty} \frac{\sin (2m - 1) \pi x}{(2m - 1)\pi}
	.\]
	We now look at the general ``see-saw'' wave\index{see-saw wave}, with $p = 1$. Here
	\[
		f(x) =
		\begin{cases}
			x(1 - \xi) & 0 \leq x < \xi, \\
			\xi(1 - x) & \xi \leq x < 1
		\end{cases}
		\text{ on } 0 \leq x < 1,
	\]
	and odd for $-1 \leq x < 0$. The Fourier series is
	\[
		f(x) = 2 \sum_{n = 1}^{\infty} \frac{\sin n \pi \xi \sin n \pi x}{(n \pi)^2}
	.\]
	For $\xi = 1/2$, we have
	\[
		f(x) = 2 \sum_{m = 1}^{\infty}(-1)^{m+1} \frac{\sin (2m - 1) \pi x}{((2m - 1)\pi)^2}
	.\]
	For $p = 2$, take $f(x) = x(1-x)/2$ on $0 \leq x < 1$, and odd for $-1 \leq x < 0$. The Fourier series is
	\[
		f(x) = 4 \sum_{m = 1}^{\infty} \frac{\sin (2m - 1) \pi x}{((2m - 1)\pi)^3}
	.\]
	Consider $f(x) = (1 - x^2)^2$, for $p = 3$. Then $a_n = \mathcal{O}(n^{-4})$.
\end{example}

\end{adjustbox}

\subsubsection{Integration of Fourier Series}%
\label{subsub:integration_of_fourier_series}

It is always valid to integrate the Fourier series of $f(x)$ term-by-term to obtain
\[
	F(x) = \int_{-L}^{x} f(x)\diff x
,\]
because $F(x)$ satisfies the Dirichlet conditions if $f(x)$ does.

\subsubsection{Differentiation of Fourier Series}%
\label{subsub:differentiation_of_fourier_series}

Differentiation needs to be done with great care. Consider the square wave. We differentiate it to get
\[
	f'(x) = 4 \sum_{m = 1}^{\infty} \cos (2m - 1) \pi x
.\]
But this is unbounded.

\begin{theorem}
	If $f(x)$ is continuous and satisfies the Dirichlet conditions, and $f'(x)$ satisfies the Dirichlet conditions, then $f'(x)$ can be found by term-by-term differentiation of the Fourier series of $f(x)$.
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	If we differentiate the see-saw with $\xi = 1/2$, then we get an offset square wave.
\end{example}

\end{adjustbox}

\subsection{Parseval's Theorem}%
\label{sub:parseval_s_theorem}\index{Parseval's theorem}

This gives the relation between the integral of the square of a function and the sum of the squares of the Fourier coefficients:

\begin{align*}
	\int_{0}^{2L}[f(x)]^2\diff x &= \int_{0}^{2L}\diff x \left[ \frac{1}{2} a_0 + \sum_{n}a_n \cos \frac{n \pi x}{L} + \sum_{n}b_n \sin \frac{n \pi x}{L} \right]^2 \\
				   &= \int_{0}^{2L}\diff x \left[ \frac{1}{4} a_0^2 + \sum_{n} a_n^2 \cos^2 \frac{n \pi x}{L} + \sum_{n} b_n^2 \sin^2 \frac{n \pi x}{L} \right]\\
				   &= L \left[ \frac{1}{2} a_0^2 + \sum_{n = 1}^{\infty} (a_n^2 + b_n^2) \right].
\end{align*}

This is also called the \textbf{completeness relation}\index{completeness relation} because the left hand side is always greater than equal to the right hand side if any basis is missing.

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Take the sawtooth wave. We have
	\[
	LHS = \int_{-L}^{L} x^2\diff x = \frac{2}{3}L^3
	,\]
	\[
	RHS = L \sum_{n = 1}^{\infty} \frac{4L^2}{n^2 \pi^2} = \frac{4L^3}{\pi ^2}\sum_{n = 1}^{\infty} \frac{1}{n^2}
	.\]

\end{example}

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
Therefore, we obtain
\[
\sum_{n = 1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}
.\]
\end{adjustbox}

\subsection{Alternative Fourier Series}%
\label{sub:alternative_fourier_series}

\subsubsection{Half-range Series}%
\label{subsub:half_range_series}\index{half-range series}

Consider $f(x)$ defined only on $0 \leq x < L$. Then we can extend its range over $- L \leq x < L$ in two simple ways:
\begin{enumerate}[(i)]
	\item Require it to be odd, so $f(-x) = -f(x)$. Then $a_n = 0$, and
		\[
			b_n = \frac{2}{L} \int_{0}^{L} \sin \frac{n \pi x}{L}\diff x
		.\]
		This is a Fourier sine series.
	\item Require it to be even, so $f(-x) = f(x)$. Then $b_n = 0$,
		\[
			a_n = \frac{2}{L} \int_{0}^{L}f(x) \cos \frac{n \pi x}{L}\diff x
		.\]
		This is a Fourier cosine series.
\end{enumerate}

\subsubsection{Complex Representation}%
\label{subsub:complex_representation}

Recall that
\[
	\cos \frac{n \pi x}{L} = \frac{1}{2} \left( e^{i n \pi x/L} + e^{-i n \pi x/L}\right), \quad \sin \frac{n \pi x}{L} = \frac{1}{2i} \left(e^{i n \pi x/L} - e^{-i n \pi x/L}\right)
.\]
So our Fourier series becomes
\begin{align*}
	f(x) &= \frac{1}{2} a_0 + \sum_{n = 1}^{\infty}a_n \cos \frac{n \pi x}{L} + \sum_{n = 1}^{\infty} b_n \sin \frac{n \pi x}{L} \\
	     &= \frac{1}{2} a_0 + \frac{1}{2} \sum_{n = 1}^{\infty}(a_n - i b_n) e^{i n \pi x/L} + \frac{1}{2} \sum_{n = 1}^{\infty}(a_n + i b_n) e^{-i n \pi x/L} \\
	     &= \sum_{m = -\infty}^{\infty} c_m e^{i m \pi x/L}.
\end{align*}
The coefficients $c_m$ satisfy
\[
c_m =
\begin{cases}
	\frac{1}{2}(a_{m} - ib_{m}) & m > 0, \\
	\frac{1}{2} a_0 & m = 0, \\
	\frac{1}{2}(a_{-m} + i b_{-m}) & m < 0.
\end{cases}
\]
Equivalently,
\[
	c_m = \frac{1}{2L}\int_{-L}^{L}f(x) e^{-i m \pi x/L}\diff x
.\]
Our inner product in the complex representation is
\[
	\langle f, g \rangle = \int f^{\ast}g \diff x
.\]
This is orthogonal, as
\[
\int_{-L}^{L} e^{-i m \pi x/L}e^{i n \pi x/L} \diff x = 2L \delta_{mn}
,\]
and satisfies Parseval's theorem as a result:
\[
	\int_{-L}^{L}|f(x)|^2\diff x = 2L \sum_{m = -\infty}^{\infty}|c_m|^2
.\]

\subsection{Fourier Series Motivations}%
\label{sub:fourier_series_motivations}

\subsubsection{Self-adjoint matrices}%
\label{subsub:self_adjoint_matrices}

Suppose $\mathbf{u}, \mathbf{v}$ are complex $N$-vectors with inner product $\langle \mathbf{u}, \mathbf{v} \rangle = \mathbf{u}^{\dagger} \mathbf{v}$. Then matrix $A$ is self-adjoint\index{self-adjoint matrix} (or Hermitian\index{Hermitian matrix}) if
\[
	\langle A \mathbf{u}, \mathbf{v} \rangle = \langle \mathbf{u}, A \mathbf{v} \rangle \implies A^{\dagger} = A
.\]
The eigenvalues $\lambda_1, \ldots, \lambda_N$ of $A$ satisfy the following properties:
\begin{enumerate}[(i)]
	\item The eigenvalues are real: $\lambda_n^{\ast} = \lambda_n$.
	\item If $\lambda_n \neq \lambda_m$, then their respective eigenvectors are orthogonal: $\langle \mathbf{v}_n, \mathbf{v}_m \rangle = 0$.
	\item If we rescale our eigenvectors then $\{\mathbf{v}_1, \ldots, \mathbf{v}_N\}$ form an orthonormal basis.
\end{enumerate}

Given $\mathbf{b}$, we can try to solve for $\mathbf{x}$ in $A \mathbf{x} = \mathbf{b}$. Express 
\[
	\mathbf{b} = \sum_{n = 1}^{N} b_n \mathbf{v}_n, \quad \mathbf{x} = \sum_{n = 1}^{N} c_n \mathbf{v}_n
.\]
Substituting into the equation,
\begin{align*}
	A \mathbf{x} &= \sum_{n = 1}^{N} A c_n \mathbf{v}_n = \sum_{n = 1}^{N} c_n \lambda_n \mathbf{v}_n, \\
	\mathbf{b} &= \sum_{n = 1}^{N} b_n \mathbf{v}_n.
\end{align*}
Equating and using orthogonality,
\[
c_n \lambda_n = b_n \implies c_n = \frac{b_n}{\lambda_n}
.\]
Hence the solution is
\[
\mathbf{x} = \sum_{n = 1}^{N}\frac{b_n}{\lambda_n} \mathbf{v}_n
.\]

\subsubsection{Solving inhomogeneous ODE with Fourier series}%
\label{subsub:solving_inhomogeneous_ode_with_fourier_series}

Take the following problem: We wish to find $y(x)$ given $f(x)$ for which
\[
	\mathcal{L}(y) = - \frac{\Diff2 y}{\diff x^2} = f(x)
,\]
subject to the boundary conditions $y(0) = y(L) = 0$. The related eigenvalue problem is 
\[
	\mathcal{L}y_n = \lambda_n y_n, \quad y_n(0) = y_n(L) = 0
.\]
This has eigenfunctions and eigenvalues
\[
	y_n(x) = \sin \frac{n \pi x}{L}, \quad \lambda_n = \left( \frac{n \pi}{L} \right)^2
.\]
Note that $\mathcal{L}$ is a self-adjoint ODE with orthogonal eigenfunctions. Thus we seek solutions as a half-range sine series. We try
\[
	y(x) = \sum_{n = 1}^{\infty} c_n \sin \frac{n \pi x}{L},
\]
and expand
\[
	f(x) = \sum_{n = 1}^{\infty} b_n \sin \frac{n \pi x}{L}
.\]
Substituting this in,
\begin{align*}
	\mathcal{L}y &= - \frac{\Diff2}{\diff x^2} \left( \sum_{n} c_n \sin \frac{n \pi x}{L} \right) = \sum_{n = 1}^{\infty} c_n \left(\frac{n \pi}{L} \right)^2 \sin \frac{n \pi x}{L} \\
		     &= \sum_{n = 1}^{\infty} b_n \sin \frac{n \pi x}{L}.
\end{align*}
By orthogonality, we have
\[
	c_n \left( \frac{n \pi}{L}\right)^2 = b_n \implies c_n = \left( \frac{L}{n \pi} \right)^2
.\]
Thus the solution is
\[
	y(x) = \sum_{n = 1}^{\infty} \left( \frac{L}{n \pi}\right)^2 b_n \sin \frac{n \pi x}{L} = \sum_{n = 1}^{\infty} \frac{b_n}{\lambda_n} y_n
.\]
This is similar to a self-adjoint matrix.

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Consider the square wave on $L = 1$, as an odd function. This has Fourier series
	\[
		f(x) = 4 \sum_{m} \frac{\sin (2m - 1)\pi x}{(2m - 1)\pi}
	.\]
	So the solution should be
	\[
		y(x) = \sum \frac{b_n}{\lambda_n} y_n = 4 \sum_{m} \frac{\sin (2m - 1)\pi x}{((2m -1)\pi)^3}
	.\]
	This is the Fourier series for $y(x) = x(1-x)/2$.
\end{example}

\end{adjustbox}

\newpage

\section{Sturm-Liouville theory}%
\label{sec:sturm_liouville_theory}

\subsection{Second-order linear ODEs}%
\label{sub:second_order_linear_odes}

We wish to solve a general inhomogeneous ODE
\[
	\mathcal{L}y = \alpha(x) y'' + \beta(x) y' + \gamma(x) y = f(x)
.\]
\begin{itemize}
	\item The \textbf{homogeneous} equation $\mathcal{L} y = 0$ has two independent solutions $y_1(x)$, $y_2(x)$. The \textbf{complementary function}\index{complementary function} $y_c(x)$ is the general solution of
		\[
			y_c(x) = A y_1(x) +B y_2(x)
		,\]
		where $A, B$ are constants.
	\item The \textbf{inhomogeneous} equation $\mathcal{L}y = f(x)$ has a special solution, the \textbf{particular integral}\index{particular integral} $y_p(x)$. The general solution is then
		\[
			y(x) = y_p(x) + Ay_1(x) + By_2(x)
		.\]
	\item Two \textbf{boundary} or \textbf{initial} conditions are required to determine $A, B$:
		\begin{enumerate}[(a)]
			\item \textbf{Boundary conditions}\index{boundary conditions} require us to solve the equation on $a < x < b$ given $y$ at $x = a, b$ (Dirichlet conditions), or given $y'$ at $x = a, b$ (Neumann conditions), or given a mixed value $y + ky'$. Boundary conditions are often assumed to be $y(a) = y(b)$, to admit the trivial solution $y \equiv 0$. This can be done by adding complementary functions
				\[
				\tilde y = y + A_1 y_1 + B y_2
				.\]
			\item \textbf{Initial condition}\index{initial conditions} require us to solve the equation for $x \geq a$, given $y$ and $y'$ at $x = a$.
		\end{enumerate}
		
\end{itemize}

\subsubsection{General eigenvalue problem}%
\label{subsub:general_eigenvalue_problem}

To solve the equation employing eigenfunction expansion, we are required to solve the related eigenvalue problem
\[
	\alpha(x) y'' + \beta(x) y' + \gamma(x) y = - \lambda \rho(x) y
,\]
with specified boundary conditions. This forms often occurs in higher dimensions, after separation of variables.

\subsection{Self-adjoint operators}%
\label{sub:self_adjoint_operators}

For two complex-valued functions $f, g$ on $a \leq x \leq b$, we can define the \textbf{inner product}\index{inner product of complex-valued functions}
\[
	\langle f, g \rangle = \int_{a}^{b} f^{\ast}(x) g(x)\diff x
.\]
The norm is then $\|f\| = \langle f, f \rangle^{1/2}$.

\subsubsection{Sturm-Liouville equation}%
\label{subsub:sturm_liouville_equation}

The eigenvalue problem greatly simplifies if $\mathcal{L}$ is \textbf{self-adjoint}, that is, it can be expressed in \textbf{Sturm-Liouville form}\index{Sturm-Liouville form}
\[
	\mathcal{L} y \equiv - (\rho y')' + q y = \lambda \omega y
,\]
where the \textbf{weight function}\index{weight function} $\omega(x)$ is non-negative. We can convert to Sturm-Liouville form by multiplying by an integrating factor $F(x)$ to find
\[
F \alpha y'' + F \beta y' + F \gamma y = - \lambda F \rho y
.\]
This gives
\[
	\frac{\diff}{\diff x} (F \alpha y') - F' \alpha y' - F \alpha' y' + F \beta y' + F \gamma y = - \lambda F \rho y
.\]
Eliminating $y'$ terms, we require
\[
	F' \alpha = F(\beta - \alpha') \implies \frac{F'}{F} = \frac{\beta - \alpha'}{\alpha}
.\]
Solving, we get
\[
	F(x) = \exp \left( \int^{x} \frac{(\beta - \alpha')}{\alpha} \diff x \right)
,\]
and $(F \alpha y')' + F \gamma y = - \lambda F \rho y$. So $\rho(x) = F(x) \alpha (x)$, $q(x) = - F(x) \gamma(x)$, and $\omega(x) = F(x) \rho(x)$. This is non-negative as $F(x) > 0$.

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Take the Hermite equation
	\[
	y'' - 2xy' + 2n y = 0
	.\]
	Putting this into Sturm-Liouville form, we have $\alpha = 1$, $\beta - 2x$, $\gamma = 0$ and $\lambda \rho = 2n$. Thus we take
	\[
		F = \exp \left( \int^{x} \frac{-2x}{2} \diff x \right) = e^{-x^2}
	.\]
	Hence
	\[
		\mathcal{L} y \equiv -(e^{-x^2} y')' = 2n e^{-x^2}y
	.\]
\end{example}

\end{adjustbox}

\subsubsection{Self-adjoint definition}%
\label{subsub:self_adjoint_definition}

A linear operator $\mathcal{L}$ is \textbf{self-adjoint}\index{self-adjoint operator} on $a \leq x \leq b$ for all pairs of functions $y_1, y_2$ satisfying boundary conditions, if
\[
	\langle y_1, \mathcal{L}y_2 \rangle = \langle \mathcal{L}y_1, y_2 \rangle
,\]
or
\[
	\int_{a}^{b} y^{\ast}_1(x) \mathcal{L}y_2(x)\diff x = \int_{a}^{b} (\mathcal{L}y_1(x))^{\ast} y_2(x) \diff x
.\]

Substituting the Sturm-Liouville form into this equation gives
\begin{align*}
	\langle y_1, \mathcal{L}y_2 \rangle - \langle \mathcal{L}y_1, y_2 \rangle &= \int_{a}^{b} [-y_1(\rho y_2')' + y_1qy_2 + y_2(\rho y_1')' - y_2 qy_1]\diff x \\
										  &= \int_{a}^{b} [-(\rho y_1 y_2')' + (\rho y_1' y_2)']\diff x \\
										  &= \left[ - \rho y_1 y_2' + \rho y_1' y_2 \right]_{a}^{b} = 0.
\end{align*}
for given boundary conditions at $x = a, b$. Suitable boundary conditions include:
\begin{itemize}
	\item $y(a) = y(b) = 0$, $y'(a) = y'(b) = 0$, or mixed boundary condition $y + ky' = 0$;
	\item Periodic functions $y(a) = y(b)$;
	\item Singular points of the ODE $\rho(a) = \rho(b) = 0$;
	\item Combinations of the above.
\end{itemize}

\subsection{Properties of self-adjoint operators}%
\label{sub:properties_of_self_adjoint_operators}

Self-adjoint operators satisfy many similar properties to self-adjoint matrices:
\begin{enumerate}[1.]
	\item The eigenvalues $\lambda_n$ are real.
	\item The eigenfunctions $y_n$ are orthogonal.
	\item The eigenfunctions $y_n$ form a complete set.
\end{enumerate}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:} 
\begin{enumerate}[1.]
	\item Given $\mathcal{L}y_n = \lambda_n \omega y_n$, we take the complex conjugate $\mathcal{L}y_n^{\ast} = \lambda_n^{\ast} \omega y_n^{\ast}$. Then,
		\[
			0 = \int_{a}^{b} (y_n^{\ast} \mathcal{L}y_n - (\mathcal{L}y_n^{\ast}) y_n)\diff x = (\lambda_n - \lambda_n^{\ast}) \int_{a}^{b} \omega y_n y_n^{\ast}\diff x
		.\]
		But the right hand side is non-zero, unless $\lambda_n = \lambda_n^{\ast}$, so the eigenvalues are real.
	\item Consider two eigenfunctions $\mathcal{L}y_m = \lambda_m \omega y_m$, $\mathcal{L}y_n = \lambda_n \omega y_n$. Then
		\[
			0 = \int_{a}^{b}(y_m \mathcal{L}y_n - y_n \mathcal{L}y_m) \diff x = (\lambda_n - \lambda_n) \int_{a}^{b} \omega y_n y_m \diff x
		.\]
		Since $\lambda_m \neq \lambda_n$, we get
		\[
		\int_{a}^{b} \omega y_n y_m \diff x = 0
		.\]
		We say $y_n, y_m$ are orthogonal with respect to the weight function $\omega(x)$ on the interval $a \leq x \leq b$. Define the inner product with respect to the weight $\omega(x)$ as
		\[
			\langle f, g \rangle_{\omega} = \int_{a}^{b} \omega(x) f^{\ast}(x) g(x) \diff x = \langle \omega f, g \rangle = \langle f, \omega g\rangle
		.\]
	\item Completeness implies we can approximate any well-behaved function $f(x)$ on $a \leq x \leq b$ by the series
		\[
			f(x) = \sum_{n = 1}^{\infty} a_n y_n(x)
		.\]
\end{enumerate}

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{enumerate}
	\item[]	To find the expansion coefficients we consider
		\[
			\int_{a}^{b} \omega(x) y_m(x) f(x) \diff x = \sum_{n = 1}^{\infty} a_n \int_{a}^{b} \omega y_n y_m \diff x = a_m \int_{a}^{b} \omega y_m^2\diff x
		.\]
		Hence
		\[
			a_n = \frac{\int_{a}^{b} \omega(x) y_n(x) f(x) \diff x}{\int_{a}^{b}\omega(x) y_n^2(x)\diff x}
		.\]
		Normally, we have normalized eigenfunctions\index{normalized eigenfunction}, where we take
		\[
			Y_n(x) = \frac{y_n(x)}{\left( \int_{a}^{b}\omega y_n^2 \diff x \right)^{1/2}}
		.\]
		This gives
		\[
			\langle Y_n, Y_m \rangle_{\omega} = \delta_{nm}
		,\]
		so
		\[
			f(x) = \sum_{n = 1}^{\infty} A_n Y_n(x)
		,\]
		where
		\[
		A_n = \int_{a}^{b} \omega Y_n f \diff x
		.\]
\end{enumerate}

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Recall the Fourier Series in Sturm-Liouville form
	\[
	\mathcal{L}y_n = -\frac{\Diff2 y_n}{\diff x^2} = \lambda_n y_n
	,\]
	with $\lambda_n = (n\pi/L)^2$ by orthogonality relations.
\end{example}

\end{adjustbox}

\subsection{Completeness and Parseval's Identity}%
\label{sub:completeness_and_parseval_s_identity}

Consider
\begin{align*}
	\int_{a}^{b}\left[ f(x) - \sum_{n = 1}^{\infty} a_n y_n \right]^2\omega \diff x &= \int_{a}^{b} \left[f^2 - 2f \sum_{n}a_n y_n + \sum_{n}a_n^2 y_n^2\right] \omega \diff x \\
											&= \int_{a}^{b}\omega f^2 \diff x - \sum_{n = 1}^{\infty}a_n^2 \int_{a}^{b}\omega y_n^2 \diff x,
\end{align*}
because
\[
\int_{a}^{b} f y_n \omega \diff x = a_n \int_{a}^{b} \omega y_n^2 \diff x
.\]
Hence if the eigenfunctions are \textbf{complete} then the series converges, and we get
\[
\int_{a}^{b} \omega f^2 \diff x = \sum_{n = 1}^{\infty} a_n^2 \int_{a}^{b} \omega y_n^2 \diff x = \sum_{n = 1}^{\infty} A_n^2
.\]
We also get \textbf{Bessel's inequality}\index{Bessel's inequality}, by looking at what happens if some eigenfunctions are missing:
\[
\int_{a}^{b} \omega f^2 \diff x \geq \sum_{n = 1}^{\infty} A_n^2
.\]
We define the partial sums
\[
	S_N(x) = \sum_{n = 1}^{N}a_n y_n
.\]
The error in the partial sum
\[
	\epsilon_N = \int_{a}^{b} \omega[f(x) - S_N(x)]^2\diff x \to 0
.\]
is minimized by the sequence defined as above, as
\begin{align*}
	\frac{\partial \epsilon_N}{\partial a_n} &= \frac{\partial}{\partial a_n} \left[ \int_{a}^{b} \omega \left[f(x) - \sum_{n = 1}^{N}a_n y_n\right]^2 \diff x \right] \\
						 &= - 2 \int_{a}^{b} y_n \omega \left[f - \sum_{n = 1}^{N} a_n y_n\right]\diff x \\
						 &= -2 \int_{a}^{b}(\omega f y_n - a_n \omega y_n^2)\diff x = 0.
\end{align*}

\subsection{Legendre Polynomials}%
\label{sub:legendre_polynomials}

Consider Legendre's equation\index{Legendre's equation} arising from spherical polar coordinates
\[
	(1 - x^2)y'' - 2xy' + \lambda y = 0
\]
on the interval $-1 \leq x \leq 1$ with $y$ finite at $x = \pm 1$. This is in Sturm-Liouville form with $\rho = 1-x^2$, $q = 0$, $\omega = 1$. To solve, we seek a power series about $x = 0$. Let
\[
y = \sum_{n = 0}^{\infty} c_n x^{n}
.\]
Then substituting,
\[
	(1 - x^2)\sum_{n = 0}^{\infty} n(n-1) c_n x^{n-2} - 2x \sum_{n = 0}^{\infty} n c_n x^{n-1} + \lambda \sum_{n = 0}^{\infty} c_n x^{n} = 0
.\]
Equating powers of $x^{n}$, we get
\[
	(n+2)(n+1)c_{n+2} - n(n-1)c_n - 2n c_n + \lambda c_n = 0
,\]
\[
	\implies c_{n+2} = \frac{n(n+1) - \lambda}{(n+1)(n+2)} c_n
.\]
So specifying $c_0, c_1$ gives two independent solutions,
\begin{align*}
	y_{even} &= c_0 \left[ 1 + \frac{(-\lambda)}{2!}x^2 + \frac{(6 - \lambda)(-\lambda)}{4!}x^{4} + \cdots \right], \\
	y_{odd} &= c_1 \left[x + \frac{(2 - \lambda)}{3!}x^3 + \frac{(12 - \lambda)(2 - \lambda)}{5!}x^{5} + \cdots \right].
\end{align*}
But as $n \to \infty$, the ratio of terms tends to $1$, so the radius of convergence is $|x| < 1$. This means this series is divergent at $x = \pm 1$.

However, we can use finiteness to our advantage. Take $\lambda = l(l+1)$ with $l$ an integer. Then one of the series terminates. These \textbf{Legendre polynomials}\index{Legendre polynomials} $P_l(x)$ are eigenfunctions on $-1 \leq x \leq 1$ with normalization convention $P_l(1) = 1$. The first few values are
\begin{align*}
	l &= 0, & \lambda &= 0, & P_0(x) &= 1, \\
	l &= 1, & \lambda &= 2, & P_1(x) &= x, \\
	l &= 2, & \lambda &= 6, & P_2(x) &= (3x^2-1)/2, \\
	l &= 3, & \lambda &= 12, & P_3(x) &= (5x^3 - 3x)/2.
\end{align*}
As these are in Sturm-Liouville form, we get
\[
\int_{-1}^{1}P_n P_m\diff x = 0, \quad \int_{-1}^{1}P_n^2\diff x = \frac{2}{2n+1}
.\]
The normalization can be proven with Rodrigues' formula
\[
	P_n(x) = \frac{1}{2^{n}x!} \left( \frac{\diff}{\diff x} \right)^{n} (x^2 - 1)^{n}
.\]
We can also take the generating function
\[
	\sum_{n = 0}^{\infty} P_n(x)t^{n} = \frac{1}{\sqrt{1 - 2xt + t^2}}
,\]
then using the binomial expansion gives $P_n$. We also have recursive formulas
\begin{align*}
	(l+1)P_{l+1}(x) &= (2l+1)xP_l(x) - lP_{l-1}(x), \\
	(2l+1)P_{l}(x) &= \frac{d}{dx} (P_{l+1}(x) - P_{l-1}(x)).
\end{align*}
The Legendre polynomials are complete, so any function on $-1 \leq x \leq 1$ can be expressed as
\[
	f(x) = \sum_{l = 0}^{\infty} a_l P_l(x)
,\]
where
\[
	a_l = \frac{2l+1}{2} \int_{-1}^{1}f(x) P_n(x)\diff x
.\]

\subsection{Sturm-Liouville Theory and Inhomogeneous ODEs}%
\label{sub:sturm_liouville_theory_and_inhomogeneous_odes}

Consider the inhomogeneous ODE on $a \leq x \leq b$:
\[
	\mathcal{L}y = f(x) - \omega(x) F(x)
.\]
Given eigenfunctions $y_n(x)$ satisfying
\begin{align*}
	\mathcal{L}y_n & \lambda_n \omega y_n, \\
	y(x) &= \sum_{n} c_n y_n(x), \\
	F(x) &= \sum_{n}a_n y_n(x),
\end{align*}
we can find the coefficients
\[
a_n = \int_{a}^{b} \omega F y_n \diff x / \int_{a}^{b} \omega y_n^2\diff x
.\]
Substituting this, we have
\[
\mathcal{L}y = \mathcal{L}\sum_{n}c_n y_n = \sum_{n} c_n \lambda_n \omega y_n = \omega \sum_{n} a_n y_n
.\]
Hence, by orthogonality, $c_n \lambda_n = a_n$, giving
\[
	y(x) = \sum_{n = 1}^{\infty} \frac{a_n}{\lambda_n} y_n(x)
.\]
This assumes $\lambda_n \neq 0$.

Generalizing, if we have a linear response term, as is often induced by a driving force,
\[
	\mathcal{L}y - \tilde \lambda \omega y = f(x)
.\]
The solution becomes
\[
	y(x) = \sum_{n = 1}^{\infty} \frac{a_n}{\lambda_n - \tilde \lambda} y_n(x)
.\]
This assumes $\tilde \lambda \neq \lambda_n$.

\subsubsection{Integral solution and Green's function}%
\label{subsub:integral_solution_and_green_s_function}

Recall that
\[
	y(x) = \sum_{n = 1}^{\infty}\frac{a_n}{\lambda_n} y_n(x) = \sum_{n} \frac{y_n(x)}{\lambda_n \mathcal{N}} \int_{a}^{b} \omega(\xi) F(\xi) y_n(\xi)\diff \xi
,\]
where $\mathcal{N} = \int \omega y_n^2 \diff x$. Then, we can continue rewriting as
\[
	\int_{a}^{b} \sum_{n = 1}^{\infty} \frac{y_n(x) y_n(\xi)}{\lambda_n \mathcal{N}_n} \omega(\xi) F(\xi)\diff \xi = \int_{a}^{b}G(x, \xi) f(\xi)\diff \xi
,\]
where
\[
	G(x, \xi) = \sum_{n = 1}^{\infty} \frac{y_n(x) y_n(\xi)}{\lambda_n \mathcal{N}_n}
\]
is the eigenfunction expansion of the Green's function\index{Green's function}. Note that $G(x, \xi)$ depends only on $\mathcal{L}$ and the boundary conditions, not on the forcing term $f(x)$: it acts like $\mathcal{L}^{-1}$.

\newpage

\part{PDEs on Bounded Domains}%
\label{prt:pdes_on_bounded_domains}

\section{The Wave Equation}%
\label{sec:the_wave_equation}

\subsection{Waves on an elastic string}%
\label{sub:waves_on_an_elastic_string}

Consider small displacements on a stretched string with fixed ends at $x = 0$ and $x = L$, with boundary conditions $y(0, t) = y(L, t) = 0$, and initial conditions
\[
	y(x, 0) = p(x), \quad \frac{\partial y}{\partial t}(x, 0) = q(x)
.\]
We derive the equation of motion by balancing forces on the segment $(x, x + \delta x)$, and taking $\delta x \to 0$. Then the boundary of the string on the segment induces forces $T_1, T_2$ at angles $\theta_1, \theta_2$ to the horizontal.

Assume that $|\partial y/\partial x| \ll 1$, so $\theta_1$, $\theta_2$ are small.

\begin{itemize}
	\item Resolving in the $x$-direction, $T_1 \cos \theta_1 = T_2 \cos \theta_2$, so $T_1 \approx T_2 = T$. Hence, tension $T$ is a constant independent of $x$, up to $\mathcal{O}(|\partial y/\partial x|^2)$.
	\item Resolving in the $y$-direction,
		\begin{align*}
			F_T &= T_2 \sin \theta_2 - T_1 \sin \theta_1 \approx T \left( \left. \frac{\partial y}{\partial x}\right|_{x + \delta x} \!\!\!\!\!\! - \left. \frac{\partial y}{\partial x} \right|_{x}\right) \\
			    &= T \frac{\partial^2 y}{\partial x^2} \delta x.
		\end{align*}
\end{itemize}

Hence, by Newton's law,
\begin{align*}
	F &= ma = (\mu \delta x) \frac{\partial^2 y}{\partial t^2} = F_T + F_g \\
	&= T \frac{\partial^2 y}{\partial x^2} \delta x - g \mu \delta x,
\end{align*}
where $\mu$ is the mass per unit length. define the wave speed as $c = \sqrt{T/\mu}$, and we find
\[
\frac{\partial^2 y}{\partial t^2} = \frac{T}{\mu} \frac{\partial^2 y}{\partial x^2} - g = c^2 \frac{\partial^2 y}{\partial x^2} - g
.\] 
Assume gravity is negligible. Then we have the 1-dimensional wave equation
\[
\frac{1}{c^2} \frac{\partial^2 y}{\partial t^2} = \frac{\partial^2 y}{\partial x^2}
.\]

\subsection{Separation of Variables}%
\label{sub:separation_of_variables}

We wish to solve the wave equation subject to boundary conditions and initial conditions. Consider possible solution of separable form
\[
	y(x, t) = X(x) T(t)
.\]
Substitute in the wave equation
\[
\frac{1}{c^2} X \ddot T = X'' T \implies \frac{1}{c^2} \frac{\ddot T}{T} = \frac{X''}{X}
.\]
But the left hand side depends only on $t$, while the right hand side depends only on $x$. This means both sides must be equal to a constant $\lambda$. Hence
\begin{align*}
	X'' + \lambda X &= 0, \\
	\ddot T + \lambda c^2 T &= 0.
\end{align*}

\subsection{Boundary Conditions and Normal Modes}%
\label{sub:boundary_conditions_and_normal_modes}

We have three possibilities for $\lambda$.
\begin{enumerate}[(i)]
	\item $\lambda < 0$. We have $\chi^2 = - \lambda$ for the characteristic polynomial, so
		\[
			X(x) = A e^{\chi x} + Be^{-\chi x} = \tilde A \cosh \chi x + \tilde B \sinh \chi x
		.\]
		But the boundary conditions $X(0) = X(L) = 0$ imply $\tilde A = \tilde B = 0$, giving the trivial solution.
	\item $\lambda = 0$. Then $X(x) = Ax + B$, again giving $A = B = 0$.
	\item $\lambda > 0$. Then $X(x) = A \cos \sqrt \lambda x + B \sin \sqrt \lambda L = 0$. Since $X(0) = 0$, $A = 0$, and $X(L) = 0$ gives $\sqrt \lambda L = n \pi$, so
		\[
			X_n(x) = B_n \sin \frac{n \pi x}{L}, \quad \lambda_n = \left( \frac{n \pi}{L}\right)^2
		.\]
		These are the normal modes\index{normal modes} because the spatial shape in $x$ does not change in time.
\end{enumerate}

\subsection{Initial Conditions and Temporal Solutions}%
\label{sub:initial_conditions_and_temporal_solutions}

Substituting the eigenvalues $\lambda_n$ into the time ODE:
\[
\ddot T + \frac{n^2 \pi^2 c^2}{L^2} T = 0
.\]
This gives
\[
	T_n(t) = C_n \cos \frac{n \pi ct}{L} + D_n \sin \frac{n \pi ct}{L}
.\]
Thus a specific solution to the wave equation is
\[
	y_n(x, t) = T_n(t)X_n(x) = \left(c_n \cos \frac{n \pi ct}{L} + D_n \sin \frac{n \pi ct}{L} \right) \sin \frac{n \pi x}{L}
.\]
Since the wave equation and boundary conditions are linear, we can add the solutions together to find the general string solution
\[
	y(x, t) = \sum_{n = 1}^{\infty} \left( c_n \cos \frac{n \pi ct}{L} + D_n \sin \frac{n \pi ct}{L} \right) \sin \frac{n \pi x}{L}
.\]
By construction, this satisfies boundary conditions, so now we need to impose the initial conditions. For $t = 0$, we have
\[
	y(x, 0) = p(x) = \sum_{n = 1}^{\infty} c_n \sin \frac{n \pi x}{L}
,\]
\[
	\frac{\partial y}{\partial t}(x, 0) = q(x) = \sum_{n = 1}^{\infty} \frac{n \pi c}{L} D_n \sin \frac{n \pi x}{L}
.\]
Hence the coefficients are given by a Fourier sine series
\begin{align*}
	C_n &= \frac{2}{L} \int_{0}^{L}p(x) \sin \frac{n \pi x}{L} \diff x, \\
	D_n &= \frac{2}{n \pi c} \int_{0}^{L}q(x) \sin \frac{n \pi x}{L} \diff x.
\end{align*}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Pluck a string at $x = \xi$, drawing it back as
	\[
		y(x, 0) = \rho(x) =
		\begin{cases}
			x(1 - \xi) & 0 \leq x \leq \xi, \\
			\xi(1 - x) & \xi \leq x \leq 1,
		\end{cases}
	\]
	\[
		\frac{\partial y}{\partial t} (x, 0) = q(x) = 0
	.\]
	Then by Fourier series, $C_n = (2 \sin n \pi \xi)/(n \pi)^2$, $D_n = 0$. Thus we have the solution
	\[
		y(x, t) = \sum_{n = 1}^{\infty} \frac{2}{(n \pi)^2} \sin n \pi \xi \sin n \pi x \cos n \pi c t
	.\]
	Taking $\xi = 1/2$, we get $c_2m = 0$, $c_{2m-1} = 2(-1)^{m+1}/((2m-1)\pi)^2$. For a guitar, we typically have $1/4 \leq \xi \leq 1/3$, and for a violin we have $\xi \approx 1/7$.
\end{example}

\end{adjustbox}

Note, if we recall the sine and cosine summation identities, we can rewrite our solution as
\begin{align*}
	y(x, t) &= \frac{1}{2} \sum_{n = 1}^{\infty}\biggl[ c_n \sin \frac{n \pi}{L} (x - ct) + D_n \cos \frac{n \pi}{L} (x - ct) \\
		&+ C_n \sin \frac{n \pi}{L} (x + ct) + D_n \cos \frac{n \pi}{L} (x + ct) \biggr] = f(x - ct) + g(x + ct)
\end{align*}
The standing wave solution is made up of a right-moving wave and a left-moving wave.

\subsection{Oscillation Energy}%
\label{sub:oscillation_energy}

A vibrating string has kinetic energy due to its motion:
\[
	KE = \frac{1}{2} \mu \int_{0}^{L} \left( \frac{\partial y}{\partial t}\right)^2 \diff x
\]
and potential energy due to stretching
\[
	PE = T \Delta X = T \int_{0}^{L} \left( \sqrt{1 + \left( \frac{\partial y}{\partial x} \right)^2} - 1 \right) \diff x \approx \frac{1}{2} T \int_{0}^{L} \left( \frac{\partial y}{\partial x}\right)^2 \diff x
.\]
The total summed energy becomes (using $c^2 = T/\mu$)
\[
	E = \frac{1}{2} \mu \int_{0}^{L} \left[ \left( \frac{\partial y}{\partial t} \right)^2 + c^2 \left( \frac{\partial y}{\partial x} \right)^2 \right] \diff x
.\]
Substituting and using orthogonality,
\begin{align*}
	E =& \frac{1}{2} \mu \sum_{n = 1}^{\infty} \int_{0}^{L} \biggl[ \left( \frac{- n \pi c}{L} C_n \sin \frac{n \pi c t}{L} + \frac{n \pi c}{L}D_n \cos \frac{n \pi c t}{L} \right)^2 \sin^2 \frac{n \pi x}{L} \\
	  & \quad + c^2 \left( C_n \cos \frac{n \pi c t}{L} + D_n \sin \frac{n \pi c t}{L} \right)^2 \frac{n^2 \pi^2}{L^2} \cos^2 \frac{n \pi x}{L} \biggr]\diff x \\
		=& \frac{1}{4} \mu \sum_{n = 1}^{\infty} \frac{n^2 \pi^2 c^2}{L}(C_n^2 + D_n^2).
\end{align*}
This is the sum of the energy of the normal modes, and is constant, hence energy is conserved in time.

\subsection{Wave Reflection and Transmission}%
\label{sub:wave_reflection_and_transmission}

Recall the travelling wave solution. A simple harmonic traversing wave is
\[
	y = \Re \bigl[ A e^{iw (t - x/c)} \bigr] = |A| \cos \left( w - \left( t - \frac{x}{c} \right) + \phi \right)
,\]
where the phase is $\phi = \arg A$, and the wavelength is $2 \pi c / \omega$. Consider a density discontinuity on a string at $x = 0$, with
\[
\mu =
\begin{cases}
	\mu_{-} & x < 0 \implies c_{-} = \sqrt{T/\mu_{-}}, \\
	\mu_{+} & x > 0 \implies c_{+} = \sqrt{T/\mu_{+}}.
\end{cases}
\]
We will assume constant tension. Consider the incident wave on the junction. $Ae^{i \omega(t - x/c_{-})}$. Then it will split into a reflected wave $Be^{i \omega(t + x/c_{-})}$ and a transmitted wave $De^{i\omega(t - x/c_{+})}$. 

The boundary conditions at $x = 0$ give:
\begin{itemize}
	\item The string does not break, so $y$ is continuous, implying $A + B = D$.
	\item The forces balance, so
		\[
			T \left. \frac{\partial y}{\partial x}\right|_{x = 0_{-}} = T \left. \frac{\partial y}{\partial x} \right|_{x = 0_{+}}
		,\]
		so $\partial y/\partial x$ is continuous for all $t$. Solving, this gives
		\begin{align*}
			- \frac{i \omega A}{c_{-}} + \frac{i \omega B}{c_{-}} &= - \frac{i \omega D}{c_{+}}, \\
			\implies 2A = D + D\frac{c_{-}}{c_{+}} &= \frac{D}{c_{+}}(c_{+} + c_{-}).
		\end{align*}
\end{itemize}
Hence, we have
\[
D = \frac{2 c_{+}}{c_{-} + c_{+}} A, \quad B = \frac{c_{+} - c_{-}}{C_{+} + c_{-}} A
.\]
In general, a different phase shift $\phi$ is possible. We consider the following limiting cases:
\begin{enumerate}[1)]
	\item If the string is continuous, so $c_{-} = c_{+}$, then $D = A$, $B = 0$.
	\item If we have Dirichlet boundary conditions $u_{+}/u_{-} \to \infty$, then $c_{+}/c_{-} \to 0$. This gives $D = 0$, $B = -A$, so total reflection with opposite phase.
	\item If we have Neumann boundary conditions $u_{+}/u_{-} \to 0$, then $c_{+}/c_{-} \to \infty$. This gives $D = 2A$, $B = A$, so total reflection with the same phase.
\end{enumerate}

\subsection{Wave Equation in 2D Plane Polars}%
\label{sub:wave_equation_in_2d_plane_polars}


The 2D wave equation for $u(r, \theta, t)$ is
\[
\frac{1}{c^2} \frac{\partial^2 u}{\partial t^2} = \nabla^2 u
,\]
with boundary conditions at $r = 1$ on a unit disc, often $u(1, \theta, t) = 0$, and initial conditions for $t = 0$:
\[
	u(r, \theta, 0) = \phi(r, \theta), \quad \frac{\partial u}{\partial t}(r, \theta, 0) = \psi (r, \theta)
.\]
First, we try temporal separation. Substitute
\[
	u(r, \theta, t) = T(t) V(r, \theta)
.\]
This gives
\[
\ddot T + \lambda c^2 T = 0, \quad \nabla^2 V + \lambda V = 0
.\]
In polars, this gives
\[
\frac{\partial^2 V}{\partial r^2} + \frac{1}{r} \frac{\partial V}{\partial r} + \frac{1}{r^2} \frac{\partial^2 V}{\partial \theta^2} + \lambda V
.\]
Now we can try spacial separation:
\[
	V(r, \theta) = R(r) \Theta(\theta)
.\]
This gives equations
\[
	\Theta'' + \mu \Theta = 0, \quad r^2 R'' + r R' + (\lambda r^2 - \mu)R = 0
,\]
where $\lambda, \mu$ are separation constants.

The configuration implies periodic boundary conditions, so $\Theta(0) = \Theta(2 \pi)$ with $\mu > 0$, so the eigenvalues are $\mu = m^2$ with solutions
\[
	\Theta_m(\theta) = A_m \cos m \theta + B_m \sin m \theta
.\]
Divide the radial equation by $r$ to bring it into Sturm-Liouville form with $\mu = m^2$:
\[
	\frac{\diff}{\diff r} (r R') - \frac{m^2}{r}R = - \lambda r R
,\]
where $p(r) = R$, $q(r) = m^2/r$, and weight $w(r) = r$. This has self-adjoint boundary conditions with $R(1) = 0$ and bounded at $R(0)$, since $p(0) = 0$ at a regular singular point.

This is known as Bessel's equation\index{Bessel's equation}. Substituting $z = \sqrt{\lambda} r$, we find
\[
	z^2 \frac{\Diff2 R}{\diff z^2} + z \frac{\diff R}{\diff z} + (z^2 - m^2)R = 0
.\]
We can look at a Frobenius solution by substituting a power series
\[
R = z^{p} \sum_{n = 0}^{\infty} a_n z^{n}
,\]
which gives
\[
	\sum_{n} a_n[(n+p)^2 z^{n+p} + z^{n + p + 2} - m^2z^{n+p}] = c
.\]
The indicial equation is $p^2 - m^2 = 0$, so $p = m$ or $p = -m$. We choose $p = m$ to get the regular solution, with recursion relation
\[
	(n + m)^2 a_n + a_{n-2} - m^2a_n = 0 \implies a_n = \frac{-1}{n(n+2m)}a_{n-2}
.\]
Putting $n \to 2n'$, we have
\[
	a_{2n'} = \frac{-1}{4n'(n' + m)}a_{2n'-2}
,\]
so stepping up from $a_0$, we have
\[
	a_{2n} = \frac{(-1)^{n}}{2^{2n}n!(n+m)(n+m-1)\cdots(m+1)}a_0
.\]
Take $a_0 = (2^{m}m!)^{-1}$, to find the Bessel function of the first kind\index{Bessel function of the first kind}
\[
	J_m(z) = \biggl(\frac{z}{2}\biggr)^{m} \sum_{n = 0}^{\infty} \frac{(-1)^{n}}{n!(n+m)!} \biggl( \frac{z}{2} \biggr)^{2n}
.\]

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Using $y = \sqrt z R$ in the Bessel equation, we find
	\[
		y'' + y \biggl( 1 + \frac{1}{4z} - \frac{m^2}{z^2} \biggr) = 0
	.\]
	So as $z \to \infty$, $y'' = -y$, giving solutions
	\[
		R = \frac{1}{\sqrt z}(A \cos z + B \sin z)
	.\]
\end{example}
\end{adjustbox}

These also work for $m = \mu$ if we replace $(n+m)!$ with $\Gamma(n+m+1)$. We can get a second solution with $p = -m$, which are the Neumann functions\index{Neumann functions}
\[
	Y_m(z) = \lim_{\gamma \to m} \frac{J_{\gamma}(z) \cos (\gamma \pi) - J_{-\gamma}(z)}{\sin \gamma \pi}
.\]

We can show that
\[
	\frac{\diff}{\diff z} (z^{m} J_m(z)) = z^{m}J_{m-1}(z)
,\]
and hence
\[
	J_m'(z) + \frac{m}{z}J_m(z) = J_{m-1}(z)
.\]
Repeating with $z^{-m}$ we can find the recursion relations
\begin{align*}
	J_{m-1}(z) + J_{m+1}(z) &= \frac{2m}{z} J_m(z), \\
	J_{m-1}(z) - J_{m+1}(z) &= 2 J_m'(z).
\end{align*}
For small $z \to 0$, we have
\[
	J_0(z) \to 1, \quad J_m(z) \to \frac{1}{m!} \biggl( \frac{z}{2} \biggr)^{m}
,\]
\[
	Y_0(z) \to \frac{2}{\pi} \log \biggl( \frac{z}{2} \biggr), \quad Y_m(z) \to - \frac{(m-1)!}{\pi} \biggl( \frac{2}{z} \biggr)^{m}
.\]
For large $z \to \infty$, we have oscillatory solutions
\begin{align*}
	J_m(z) &\approx \sqrt{\frac{2}{\pi z}} \cos \biggl( z - \frac{m \pi}{2} - \frac{\pi}{4} \biggr), \\
	Y_m(z) &\approx \sqrt{\frac{2}{\pi z}} \sin \biggl( z - \frac{m \pi}{2} - \frac{\pi}{4} \biggr).
\end{align*}

Define $j_{mn}$ to be the $n$'th solution to the Bessel function $J_m(z)$, so $J_m(j_{mn}) = 0$. Approximately, we get
\[
	\cos \biggl( z - \frac{m \pi}{2} - \frac{\pi}{4} \biggr) = 0
,\]
i.e.
\[
z \approx n \pi + \frac{m \pi}{2} - \frac{\pi}{4} \equiv \tilde j_{mn}
.\]
This is accurate within $10\%$.

\subsection{2D Wave Equation Solution}%
\label{sub:2d_wave_equation_solution}

We know the radial solutions to the 2D wave equation are
\[
	R_m(z) = R_m(\sqrt \lambda r) = A J_m(\sqrt \lambda r) + B Y_m(\sqrt \lambda r)
.\]
By imposing regularity at $r = 0$, we get $B = 0$. Moreover, the boundary condition $R = 0$ at $r = 1$ gives $J_m(\sqrt \lambda) = 0$. But then we must get $\lambda_{mn} = j_{mn}^{2}$.

Thus, with the polar mode, the spatial solution is
\[
	V_{mn}(r, \theta) = \Theta_m(\theta) R_{mn}(\sqrt \lambda_{mn} r) = (A_{mn} \cos m \theta + B_{mn} \sin m \theta) J_m(j_{mn} r)
.\]
The temporal solution is $\ddot T = - \lambda c^2 T$, or $T_{mn}(t) = \cos(j_{mn} ct)$ and $\sin (j_{mn} ct)$. Hence we can sum together to obtain our general solution:
\begin{align*}
	u(r, \theta, t) &= \sum_{n = 1}^{\infty}J_0(j_{0n} r) (A_{0n}\cos (j_{0n} ct) + C_{0n} \sin (j_{0n} ct)) \\
			&+ \sum_{m = 1}^{\infty} \sum_{n = 1}^{\infty} J_m(j_{nm}t)(A_{nm} \cos m \theta+ B_{mn} \sin m \theta) \cos (j_{nm} ct) \\
			&+ \sum_{m = 1}^{\infty} \sum_{n = 1}^{\infty} J_m(j_{nm}r)(C_{mn} \cos m \theta + D_{mn} \sin m \theta) \sin (j_{nm} ct).
\end{align*}
Now we impose the initial conditions at $t = 0$:
\begin{align*}
	u(r, \theta, 0) &= \phi(r, \theta) = \sum_{m = 0}^{\infty} \sum_{n = 1}^{\infty} J_m(j_{mn}r) (A_{mn} \cos m \theta + B_{mn} \sin m \theta), \\
	\frac{\partial u}{\partial t}(r, \theta, 0) &= \psi(r, \theta) = \sum_{m = 0}^{\infty} \sum_{n = 1}^{\infty} j_{mn}c J_m(j_{mn} r) (C_{mn} \cos m \theta + D_{mn} \sin m \theta).
\end{align*}
We can find the coefficients by multiplying by $J_m$, $\cos$ and $\sin$, and exploiting orthogonality. The Bessel functions satisfy
\[
	\int_{0}^{1}J_m(j_{mn}r)J_m(j_{mk}r)r \diff r = \frac{1}{2} [J_n'(j_{mn})]^2 \delta_{nk} = \frac{1}{2} [J_{m+1}(j_{mn})]^2\delta_{nk}
.\]
For example,
\[
	\int_{0}^{2\pi}\diff \theta \cos p \theta \int_{0}^{1} r \diff r J_{pq}(j_{pq} r) \phi(r, \theta) = \frac{\pi}{2} [J_{p+1}(j_{pq})]^2 A_{pq}
.\]

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Consider the initial radial profile $u(r, \theta, 0) = \phi(r) = 1 - r^2$, giving $B_{mn} = 0$ and $A_{mn} = 0$ for $m \neq 0$ and $\frac{\partial u}{\partial t} (r, \theta, 0) = 0$. This gives $C_{mn} = D_{mn} = 0$, and we need to find
	\begin{align*}
		A_{0n} &= \frac{2}{[J_1(j_{0n})]^2} \int_{0}^{1}J_0(j_{0n}r)(1 - r^2)r \diff r \\
		       &= \frac{2}{[J_1(j_{0n})]^2} \frac{J_2(j_{0n})}{j_{0n}^2} \approx \frac{J_2(j_{0n})}{n}.
	\end{align*}
\end{example}
\end{adjustbox}

\newpage

\section{The Diffusion Equation}%
\label{sec:the_diffusion_equation}

\subsection{Physical Origin of Heat Equation}%
\label{sub:physical_origin_of_heat_equation}

This applies to processes that diffuse due to spatial gradients. An early example was Fick's law\index{Fick's law} with flux $J = - D \nabla c$, with concentration $c$ and diffusion coefficient $D$. For heat flow, we have Fourier's law
\[
q = - k \nabla \theta
,\]
where $q$ is the heat flux, $k$ is the thermal conductivity, and $\theta = T$ is the temperature. In a volume $V$, the overall heat energy $Q$ is
\[
Q = \int c_v \rho \theta \diff V
.\]
The rate of change due to heat flow is
\[
\frac{\diff Q}{\diff t} = \int c_v \rho \frac{\partial \theta}{\partial t} \diff V
.\]
Integrating over the surface $S$ enclosing the volume $V$ gives
\[
	-\frac{\diff Q}{\diff t} = \int_{S} q \cdot \hat n \diff S = \int_{S}(k \nabla \theta) \cdot \hat n \diff S = \int (-k \nabla^2 \theta) \diff V
.\]
Equating these, we find
\[
	\int \biggl( c_v \rho \frac{\partial \theta}{\partial t} - k \nabla^2 \theta \biggr) \diff V = 0
.\]
Since this is true for all $V$, the integrand must vanish. This gives
\[
\frac{\partial \theta}{\partial t} - \frac{k}{c_v \rho} \nabla^2 \theta = 0
,\]
so letting $D = k/(c_v \rho)$,
\[
\frac{\partial \theta}{\partial t} = D \nabla^2 \theta
.\]
Einstein also derived this equation in a different manner, using Brownian motion. Gas particles are diffusing by scattering every $\Delta t$, with probability PDF $p(\xi)$ of moving distance $\xi$ with
\[
	\langle \xi \rangle = \int p(\xi) \xi \diff \xi = 0
.\]
Suppose the PDF after $N \Delta t$ steps is $P_{N \Delta t}(x)$, then for the $(N+1)\Delta t$ steps,
\begin{align*}
	P_{(N+1)\Delta t}(x) &= \int_{-\infty}^{\infty}p(\xi) P_{N \Delta t}(x - \xi) \diff \xi \\
			     &\approx \int_{-\infty}^{\infty}p(\xi) \biggl[ P_{N \Delta t}(x) + P_{N \Delta t}'(x)(-\xi) + P_{N \Delta t}''(x) \frac{\xi^2}{2} \biggr] \diff \xi \\
			     &\approx P_{N \Delta t}(x) - P_{N \Delta t}'(x)\langle \xi \rangle + P_{N \Delta t}''(x) \frac{\langle \xi^2 \rangle}{2}.
\end{align*}
Identifying $P_{N \Delta t}(x) = P(x, N \Delta t)$, we have
\[
	P(x, (N + 1) \Delta t) - P(x, N \Delta t) = \frac{\partial ^2}{\partial x^2} P(x, N \Delta t) \frac{\langle \xi^2 \rangle}{2}
.\]
If we assume $\langle \xi^2 \rangle/2 = D \Delta t$, then $\Delta t \to 0$ gives
\[
\frac{\partial P}{\partial t} = D \frac{\partial^2 P}{\partial x^2}
.\]
\subsection{Similarity Solutions}%
\label{sub:similarity_solutions}

The characteristic relation between variance and time suggest seeking solutions with dimensionless parameters:
\[
	\eta \equiv \frac{x}{2 \sqrt{Dt}}
.\]
So we want to find solution $\theta(x, t) = \theta(\eta)$. Changing variable,
\[
	\frac{\partial \theta}{\partial t} = \frac{\partial \eta}{\partial t} \frac{\partial \theta}{\partial \eta} = -\frac{1}{2}\frac{x}{\sqrt D t^{3/2}} \theta' = - \frac{\eta}{2t} \theta'
,\]
\[
	D \frac{\partial^2 \theta}{\partial x^2} = D \frac{\partial}{\partial x} \biggl( \frac{\partial \eta}{\partial x} \frac{\partial \theta}{\partial \eta} \biggr) = D \frac{\partial}{\partial x} \biggl( \frac{1}{2 \sqrt{Dt}} \theta' \biggr) = \frac{1}{4t} \theta''
.\]
Equating, we get
\[
\theta'' = - 2 \eta \theta'
.\]
Take $\psi = \theta'$, then
\[
\frac{\psi'}{\psi} = - 2 \eta \implies \log \psi = - \eta^2 + C
,\]
\[
\implies \psi = \theta' = C e^{-\eta^2}
.\]
Integrating, we find
\[
	\theta = C \frac{2}{\sqrt \pi} \int_{0}^{\eta} e^{-u^2} \diff u = C \erf \biggl( \frac{x}{2 \sqrt{Dt}} \biggr)
,\]
where we define the error function\index{error function} as
\[
\erf z = \frac{2}{\sqrt \pi} \int_{0}^{z} e^{-u^2}\diff u
.\]
This describes discontinuous initial conditions that spread over time.

\subsection{Heat Conduction in a Finite Bar}%
\label{sub:heat_conduction_in_a_finite_bar}

Suppose we have a uniform bar of length $2L$, with $-L \leq x \leq L$ and initial temperature
\[
	\theta(x, 0) = H(x) =
	\begin{cases}
		1 & 0 \leq x \leq L, \\
		0 & -L \leq x < 0.
	\end{cases}
,\]
and boundary conditions $\theta(L, t) = 1$ and $\theta(-L, t) = 0$.

To apply Sturm-Liouville theory, we need homogeneous boundary conditions. Thus we want to transform the boundary condition. THe problem is then to identify a steady state solution which reflects late-time behaviour.

We try $\theta_s(x) = Ax + B$, which satisfies the heat equation. To satisfy the boundary conditions, we take $A = 1/2L$, $B = 1/2$, to get
\[
	\theta_s = \frac{(x + L)}{2L}
.\]
Transforming, we can solve for
\[
	\hat \theta(x, t) = \theta(x, t) - \theta_s(x)
,\]
with homogeneous boundary conditions $\hat \theta(-L, t) = \hat \theta(L, t) = 0$, and boundary conditions $\hat \theta(x, 0) = H(x) - (x+L)/2L$.

We try $\hat \theta(x, t) = X(x)T(t)$, which gives
\[
X'' = - \lambda X, \quad \dot T = - D \lambda T
.\]
The boundary conditions imply $\lambda > $ 0, with
\[
	X(x) = A \cos \sqrt \lambda x + B \sin \sqrt \lambda x
.\]
For the even solutions,
\[
	\cos \sqrt \lambda L = 0 \implies \sqrt{\lambda_m} = \frac{m \pi}{2L}, \; m = 1, 3, 5,\ldots
\]
and the odd solutions give
\[
	\sin \lambda L = 0 \implies \sqrt{\lambda_n} = \frac{n \pi}{L}, \; n = 1, 2, 3, \ldots
\]
but the initial conditions are odd, so we take
\[
X_n = B_n \sin \frac{n \pi x}{L}, \quad \lambda_n = \frac{n^2 \pi^2}{L^2}
.\]
Putting $\lambda_n$ into the equation for time, we find
\[
	T_n(t) = C_n \exp \biggl( - \frac{Dn^2\pi^2}{L^2}t \biggr)
.\]

\newpage

\printindex

\end{document}
