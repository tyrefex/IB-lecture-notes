\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[a4paper]{geometry}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{adjustbox}
\usepackage[shortlabels]{enumitem}
\usepackage{parskip}
\makeatletter
\newcommand{\@minipagerestore}{\setlength{\parskip}{\medskipamount}}
\makeatother
\usepackage{imakeidx}
\usepackage{bbm}

\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{null}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\Orb}{Orb}
\DeclareMathOperator{\Stab}{Stab}
\DeclareMathOperator{\ccl}{ccl}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Syl}{Syl}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Fit}{Fit}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\Mkv}{Markov}


\newcommand{\incfig}[1]{%
	\def\svgwidth{\columnwidth}
	\import{./figures/}{#1.pdf_tex}
}

\setlength\parindent{0pt}

\newcommand{\course}{GRM }
\newcommand{\lecnum}{}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\pagestyle{fancy}
\fancyhf{}
\rhead{\leftmark}
\lhead{Page \thepage}
\setlength{\headheight}{15pt}

\newcommand{\mapsfrom}{\mathrel{\reflectbox{\ensuremath{\mapsto}}}}

\makeindex[intoc]

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
    pdfauthor={Ishan Nath}
}

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{IB Markov Chains}

		\vspace{1em}
		\large
		Ishan Nath, Michaelmas 2022

		\vspace{1.5em}

		\Large

		Based on Lectures by Dr. Perla Sousi

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

\setcounter{section}{-1}

\section{Introduction}%
\label{sec:introduction}

\textbf{Markov chains} are random processes (sequence of random variables) that retain no memory of the past.

\subsection{History}%
\label{sub:history}

These were first studied by Markov in 1906. Before Markov, Poisson processes and branching processes were studied. The motivation was to extend the law of large numbers to a non-iid setting.

After Markov, Kolmogorov began studying continuous time Markov chains, also known as Markov processes. An important example is Brownian motion, which is a fundamental object in modern probability theory.

Markov chains are the simplest mathematical models for random phenomena evolving in time. They are \textbf{simple} in the sense they are amenable to tools from probability, analysis and combinatorics.

Applications of Markov chains include population growth, mathematical genetics, queueing networks and Monte Carlo simulation.

\subsection{PageRank Algorithm}%
\label{sub:pagerank_algorithm}\index{PageRank}

This is an algorithm used by Google Search to rank web pages. We model the web as a directed graph, $G = (V, E)$. Here, $V$ is the set of vertices, which are associated to the website, and $(i, j) \in E$ if $i$ contains a link to page $j$.

Let $L(i)$ be the number of outgoing edges from $i$, i.e. the outdegree, and let $|V| = n$. Then we define a set of probabilities
\[
	\hat{p}_{ij} =
\begin{cases}
	\frac{1}{L(i)} & \text{if } L(i) > 0, (i, j) \in E, \\
	\frac{1}{n} & \text{otherwise}.
\end{cases}
\]

Take $\alpha \in (0,1)$, then we define $p_{ij} = \alpha \hat{p}_{ij} + (1 - \alpha) \frac{1}{n}$. Consider a random surfer, who tosses a coin with bias $\alpha$, and either goes to $\hat p$, or chooses a website uniform at random.

We wish to find an invariant distribution $\pi = \pi P$. Then $\pi_{i}$ is the proportion of time spent at webpage $i$ by the surfer. We can then rank the pages by the values of $\pi_{i}$.

\newpage

\section{Formal Setup}%
\label{sec:formal_setup}

We begin with a state space $I$, which is either finite or countable, and a $\sigma$-algebra $(\Omega, \mathcal{F}, \mathbb{P})$.

\begin{definition}
	A stochastic process $(X_n)_{n \geq 0}$ is called a \textbf{Markov chain}\index{Markov chain} if for all $n \geq 0$, and $x_{0}, x_{1} ,\ldots, x_{n+1} \in I$,
	\[
		\mathbb{P}(X_{n+1} = x_{n+1} \mid X_{n} = x_{n}, \ldots, X_{0} = x_{0}) = \mathbb{P}(X_{n+1} = x_{n+1} \mid X_{n} = x_{n})
	.\]
	If $\mathbb{P}(X_{n+1} = y \mid X_{n} = x)$ is independent of $n$ for all $x, y$, then $X$ is called \textbf{time-homogeneous}\index{time-homogeneous}. Otherwise, it is \textbf{time-inhomogeneous}.

	For a time-homogeneous Markov chain, define $P(x, y) = \mathbb{P}(X_1 = y \mid X_0 = x)$. $P$ is called the \textbf{transition matrix}\index{transition matrix} of the Markov chain. We have
	\[
		\sum_{y \in I} P(x, y) = \sum_{y \in I} \mathbb{P}(X_1 = y \mid X_0 = x) = 1
	.\]
	Such a matrix is called a \textbf{stochastic matrix}\index{stochastic matrix}.
\end{definition}

\begin{definition}
	$(X_n)_{n \geq 0}$ with values in $I$ is called $\Mkv(\lambda, P)$ if $X_0 \sim \lambda$ and $(X_n)_{n \geq 0}$ is a Markov chain with transition matrix $P$.
\end{definition}

There are several equivalent definitions for Markov chains.

\begin{theorem}
	$X$ is $\Mkv(\lambda, P)$ if for all $n \geq 0$, $x_0, x_1, \ldots, x_n \in I$,
	\[
		\mathbb{P}(X_0 = x_0, \ldots, X_n = x_n) = \lambda(x_0)P(x_0,x_1) \cdots P(x_{n-1}, x_n)
	.\]
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} If $X$ is $\Mkv(\lambda, P)$, then 
	\begin{align*}
		\mathbb{P}(X_n = x_n, \ldots, X_0 = x_0) &= \mathbb{P}(X_n = x_n \mid X_{n-1} = x_{n-1}, \ldots, X_0 = x_0) \times \cdots \\
							 & \times \mathbb{P}(X_1 = x_1 \mid X_0 = x_0) \mathbb{P}(X_0 = x_0) \\
							 &= \lambda(x_0)P(x_0,x_1)\cdots P(x_{n-1}, x_n).
	\end{align*}
	For the other direction, note for $n = 0$, we have $\mathbb{P}(X_0 = x_0) = \lambda(x_0)$, so $X_0 \sim \lambda$, and
	\begin{align*}
		\mathbb{P}(X_n = x_n \mid X_{n-1} = x_{n-1}, \ldots, X_0 = x_0) &= \frac{\mathbb{P}(X_n = x_n, \ldots, X_0 = x_0)}{\mathbb{P}(X_{n-1} = x_{n-1}, \ldots, X_0 = x_0)} \\
										&= P(x_{n-1}, x_n).
	\end{align*}
\end{adjustbox}

\begin{definition}
	Let $i \in I$. The $\delta_{i}$-mass at $i$ is defined by
	\[
		\delta_{ij} = \mathbbm{1}(i = j) =
		\begin{cases}
			1 & \text{if } i = j, \\
			0 & \text{otherwise}.
		\end{cases}	
	\] 
\end{definition}

\begin{definition}
	Let $X_1, \ldots, X_{n}$ be discrete random variables with values in $I$. They are independent if for all $x_1, \ldots, x_n \in I$,
	\[
		\mathbb{P}(X_1 = x_1, \ldots, X_n = x_n) = \prod_{i = 1}^{n} \mathbb{P}(X_i = x_i)
	.\]
	Let $(X_n)_{n \geq 0}$ be a sequence of random variables in $I$.They are independent if for all $i_1 < i_2 < \cdots < i_k$, and for all $x_1, \ldots, x_k \in I$,
	\[
		\mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = i_k) = \prod_{j = 1}^{k} \mathbb{P}(X_{i_j} = x_j)
	.\]
	Let $(X_n)_{n \geq 0}$ and $(Y_n)_{n \geq 0}$ be two sequences. We say $X \perp Y$, or $X$ independent to $Y$,\index{independent sequences} if for all $k, m \in \mathbb{N}$, $i_1 < \cdots < i_k$, $j_1 < \cdots < j_m$, $x_1, \ldots, x_k, y_1, \ldots, y_m$,
	\begin{align*}
		\mathbb{P}(&X_{i_1} = x_1, \ldots, X_{i_k} = x_k, Y_{j_1} = y_1, \ldots, Y_{j_m} = y_m) \\
			   &= \mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k) \mathbb{P}(Y_{j_1} = y_1, \ldots, Y_{j_m} = y_m)
	.\end{align*}
\end{definition}

\begin{theorem}[Simple Markov Property]\index{simple Markov property}
	Suppose $X$ is $\Mkv(\lambda, P)$ with values in $I$. Let $m \in \mathbb{N}$ and $i \in I$. Then conditional on $X_m = i$, the process $(X_{m+n})_{n \geq 0}$ is $\Mkv(\delta_i, P)$ and it is independent of $X_0, \ldots, X_m$.
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:} Let $x_0, \ldots, x_n \in I$. Then
\begin{align*}
	\mathbb{P}(X_m &= x_0, \ldots, X_{m+n} = x_n \mid X_m = i) \\
		       &= \delta_{ix_0} \frac{\mathbb{P}(X_m = x_0, \ldots, X_{m+n} = x_n)}{\mathbb{P}(X_m = i)}, \\
	\mathbb{P}(X_m &= x_0, \ldots, X_{m+n} = x_n) \\
		       &= \sum_{y_0,\ldots, y_{m-1}}\mathbb{P}(X_0 = y_0, \ldots, X_{m} = x_0, \ldots, X_{m+n} = x_0) \\
		       &= \sum_{y_0, \ldots, y_{m-1}} \lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, x_0) \cdots P(x_{n-1}, x_n) \\
		       &= P(x_0, x_1) \cdots P(x_{n-1}, x_n) \sum_{y_0, \ldots, y_{m-1}} \lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, x_0), \\
	\mathbb{P}(X_m &= i) = \sum_{y_0, \ldots, y_{m-1}} \lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, i).
\end{align*}

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
Putting this together, we get the probability is
\[
	\delta_{ix_0}P(x_0, x_1)\cdots P(x_{n-1}, x_n) \implies \Mkv(\delta_i, P)
.\]
Now we show independence. Let $m \leq i_1 < \cdots < i_k$. Then,
\begin{align*}
	\mathbb{P}(X_{i_1} &= x_1, \ldots, X_{i_k} = x_k, X_0 = y_0, \ldots, X_m = y_m \mid X_{m} = i) \\
			   &= \frac{\mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k, X_0 = y_0, \ldots, X_m = y_m)}{\mathbb{P}(X_m = i)} \\
			   &= \frac{\lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, y_m)}{\mathbb{P}(X_m = i)} \mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k \mid X_{m} = i) \\
			   &= \mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k \mid X_{m} = i) \mathbb{P}(X_0 = y_0, \ldots \mid X_m = i).
\end{align*}

\end{adjustbox}

Let $X \sim \Mkv(\lambda, P)$. How can we find $\mathbb{P}(X_n = x)$? Evaluating,
\begin{align*}
	\mathbb{P}(X_n = x) &= \sum_{x_0, \ldots, x_{n-1}}\mathbb{P}(X_0 = x_0, \ldots, X_n = x) \\
			    &= \sum_{x_0, \ldots, x_{n-1}} \lambda(x_0) P(x_0, x_1) \cdots P(x_{n-1}, x) = (\lambda P^{n})x.
\end{align*}
Here, $\lambda$ is a row vector, and $P^{n}$ is the $n$'th power of the transition matrix. By convention, $P^{0} = I$.

Consider the related problem of finding $\mathbb{P}(X_{n+m} = y \mid X_m = x)$. From the simple Markov property, $(X_{m+n})_{n \geq 0}$ is $\Mkv(\delta_{x}, P)$. So
\[
	\mathbb{P}(X_{n+m} = y \mid X_{m} = x) = (\delta_{x} P^{n})y = (P^{n})xy
.\]

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Take the transition matrix
	\[
	P = 
	\begin{pmatrix}
		1 - \alpha & \alpha \\
		\beta & 1 - \beta
	\end{pmatrix}
	.\] 
	Then $p_{11}(n+1) = (1 - \alpha)p_{11}(n) + \beta p_{12}(n)$. Since $p_{11}(n) + p_{12}(n) = 1$, we get the general form
	\[
		p_{11}(n) =
		\begin{dcases}
			\frac{\alpha}{\alpha + \beta} + \frac{\alpha}{\alpha + \beta}(1 - \alpha - \beta)^{n} & \alpha + \beta > 0, \\
			1 & \alpha + \beta = 0.
		\end{dcases}	
	\]
\end{example}

\end{adjustbox}

Suppose $P$ is $k \times k$ stochastic, and let $\lambda_1, \ldots, \lambda_k$ be the eigenvalues of $P$.

If $\lambda_1, \ldots, \lambda_k$ are all distinct, then $P$ is diagonalisable, so we can write
\[
P = U
\begin{pmatrix}
	\lambda_1 & 0 & \cdots & 0 \\
	0 & \lambda_2 & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & \lambda_k
\end{pmatrix}
U^{-1}
.\]
Then we get
\[
P^{n} = U
\begin{pmatrix}
	\lambda_1^{n} & 0 & \cdots & 0 \\
	0 & \lambda_2^{n} & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & \lambda_k^{n}
\end{pmatrix}
.\]
Hence $p_{11}(n) = \alpha_1 \lambda_1^{n} + \cdots + \alpha_k \lambda_k^{n}$.

If one of the eigenvalues is complex, say $\lambda_{k-1}$, then also its conjugate is an eigenvalue. Say $\lambda_{k} = \overline{\lambda_{k-1}}$. If $\lambda_{k-1} = r e^{i \theta} = r \cos \theta + i r \sin \theta$, $\lambda_k = r \cos \theta - i r \sin \theta$, then we can write the general form as
\[
	p_{11}(n) = \alpha_1 \lambda_1^{n} + \cdots + \alpha_{k-2} \lambda_{k-2}^{n} + \alpha_{k-1} r^{n} \cos n \theta + \alpha_{k} r^{n} \sin n \theta
.\]

If an eigenvalue $\lambda$ has multiplicity $r$, then we must include the term $(a_{r-1}n^{r-1} + \cdots + a_1 n + a_0) \lambda^{n}$, by Jordan Normal Form.

\subsection{Communicating Classes}%
\label{sub:communicating_classes}

\begin{definition}
	$X$ is a Markov chain with matrix $P$ on $I$. Let $x, y \in I$. We say $x \to y$ ($x$ leads to $y$) if
	\[
	\mathbb{P}_x(X_n = y \text{ for some } n \geq 0\} > 0
	.\]
	We say that $x$ and $y$ communicate\index{communicate} and $x \leftrightarrow y$ if both $x \to y$ and $y \to x$.
\end{definition}

\begin{theorem}
	The following are equivalent:
	\begin{enumerate}[\normalfont(i)]
		\item $x \to y$;
		\item There exists a sequence $x = x_0, x_1, \ldots, x_k = y$ such that $P(x_0, x_1), \ldots, P(x_{k-1}, x_k) > 0$;
		\item There exists $n \geq 0$ such that $P_{xy}(n) > 0$.
	\end{enumerate}	
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:}

We show (i) if and only if (iii). Note
\[
	\{X_n = y \text{ for some } n \geq 0 \} = \bigcup_{n \geq 0} \{X_n = y\}
.\]
If $x \to y$, then there exists $n \geq 0$ such that $\mathbb{P}_x(X_n = y) > 0$, so $P_{xy}(n) > 0$. If there exists $n \geq 0$ such that $P_x(X_n = y) > 0$, then $x \to y$.

Now we note (ii) iff (iii) as
\[
	\mathbb{P}_x(X_n = y) = \sum_{x_1, \ldots, x_{n-1}} P(x, x_1) \cdots P(x_{n-1}, y)
.\]
\end{adjustbox}

\begin{corollary}
	$\leftrightarrow$ defines an equivalence class on $I$.
\end{corollary}
\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} $x \leftrightarrow x$ as $P_{xx}(0) = 1$, and $x \leftrightarrow y \iff y \leftrightarrow x$.

	Then transitivity follows from property (ii).
\end{adjustbox}


\begin{definition}
	The equivalence classes induced by $\leftrightarrow$ on $I$ are called communicating classes\index{communicating classes}. We say that a class $C$ is closed\index{closed class} if whenever $x \in C$ and $x \to y$, then $y \in C$.

	A matrix $P$ is called irreducible\index{irreducible} if it has a single communicating class.

	A state $x$ is called absorbing\index{absorbing state} if $\{x\}$ is a closed class. Equivalently, if the Markov chain started from $x$, it would remain at $x$ forever.
\end{definition}

\begin{definition}
	For $A \subset I$, we let $T_A : \Omega \to \mathbb{N} \cup \{\infty\}$. Then we define
	\[
		T_A(\omega) = \inf \{n \geq 0 : X_n(\omega) \in A\}
	.\]
	By convention, we take $\inf(\emptyset) = \infty$. Then $T_A$ is the first hitting time\index{first hitting time} of $A$.

	Denote $h_i^{A} = \mathbb{P}_i(T_A < \infty)$. Then $h^{A} : I \to [0, 1]$ is a vector of hitting probabilities. We can also define
	\[
		k^{A} : I \to \mathbb{R}_+ \cup \{\infty\}
	,\]
	as the mean hitting time. Then
	\[
		k_i^{A} = \mathbb{E}_i[T_A] = \sum_{n =  1}^{\infty }n \mathbb{P}_i(T_A = n)
	,\]
	if $\mathbb{P}_i(T_A = \infty) = 0$.
\end{definition}

\begin{theorem}
	Let $A \subset I$. The vector $(h_i^{A} : i \in A)$ is a solution to the linear system
	\[
	h_i^{A} =
	\begin{dcases}
		1 & i \in A, \\
		\sum_{j}P(i, j) h_j^{A} & i \not \in A.
	\end{dcases}
	\]
	The vector $(h_i^{A})$ is the minimal non-negative solution to this solution.
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:} Clearly, if $i \in A$, then $h_i^{A} = 1$. So assume $i \not \in A$. Then
\begin{align*}
	h_i^{A} &= \mathbb{P}_i(T_A < \infty) = \sum_{n = 1}^{\infty} \mathbb{P}_i(X_1 \not \in A, \ldots, X_{n-1} \not \in A, X_n \in A) \\
		&= \mathbb{P}_i(X_1 \in A) + \sum_{n = 2}^{\infty} \mathbb{P}_i(X_1 \not \in A, \ldots, X_n \in A) \\
		&= \mathbb{P}_i(X_1 \in A) + \sum_{n = 2}^{\infty} \sum_{j \not \in A} \mathbb{P}_i(X_1 = j, X_2 \not \in A, \ldots, X_n \in A) \\
		&= \mathbb{P}_i(X_1 \in A) + \sum_{n = 2}^{\infty} \sum_{j \not \in A}\mathbb{P}_i(X_2 \not \in A, \ldots, X_n \in A \mid X_0 = i, X_1 = j) P(i, j) \\
		&= \mathbb{P}_i(X_1 = A) + \sum_{n = 1}^{\infty} \sum_{j \not \in A}P(i, j) \mathbb{P}_j(X_1 \not \in A, \ldots, X_n \in A) \\
		&= \sum_{j \in A}P(i, j) h_j^{A} + \sum_{j \not \in A}P(i, j) h_j^{A} \\
		&= \sum_{j} P(i, j) h_j^{A}.
\end{align*}
\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
Now we prove minimality. Let $(x_i)$ be another non-negative solution. We are required to show $h_i^{A} \leq x_i$. Assume $i \not \in A$. Then we know
\begin{align*}
	x_i &= \sum_{j}P(i, j)x_j \\
	x_i &= \sum_{j \in A}P(i, j) + \sum_{j \not \in A}P(i, j)x_j \\
	    &= \sum_{j \in A}P(i, j) + \sum_{j \not \in A}\sum_{k \in A}P(i, j)P(j, k) + \sum_{j \in A}\sum_{k \not \in A}P(i, j)P(j, k) x_k \\
	    &= \mathbb{P}_i(X_1 \in A) + \mathbb{P}_i(X_1 \not \in A, X_2 \in A) + \sum_{j \not \in A}\sum_{k \in A}P(i, j)P(j, k)x_k \\
	    &\geq \mathbb{P}_i(X_1 \in A) + \mathbb{P}_i(X_1 \not \in A, X_2 \in A) + \cdots + \mathbb{P}_i(X_1 \not \in A, \ldots, X_n \in A).
\end{align*}
Hence $x_i \geq \mathbb{P}_i(T_A \leq n)$, and since the union of these events is $\{T_A < \infty\}$, we get
\[
	x_i \geq \mathbb{P}_i(T_A < \infty) = h_i^{A}
.\] 

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Consider a simple random walk on $\mathbb{Z}_{+}$. We have a transition matrix $P(0, 1) = 1$, and $P(i, i+1) = p = 1 - P(i, i-1)$. Then we wish to find $h_i = \mathbb{P}_i(T_0 < \infty)$. We know $h_0 = 1$, and $h_i = p \cdot h_{i+1} + q h_{i-1}$. This gives
	\[
		h_i = a + b \left( \frac{q}{p} \right)^{i} = a + (1 - a) \left( \frac{q}{p} \right)^{i}
	.\]
	We assume $q > p$: to get the non-negative and minimal solution we need to take $a = 1$. Then $h_i = 1$ for all $i \geq 1$.

	Now assume $q < p$: We get $a = 0$, s $h_i = (q/p)^{i}$.

	If $p = q = 1/2$, we get $h_i = a + bi$, so by boundedness, $a = 1$, and $b = 0$. So $h_i = 1$ for all $i \geq 1$.
\end{example}

\end{adjustbox}

\subsection{Birth and Death chains}%
\label{sub:birth_and_death_chains}

The above example is almost a birth and death chain, with equal probability at each $i$. Here, we have $P(0, 0) = 1$, $P(i, i+1) = p_i$, $P(i, i-1) = q_i$.

We have $h_i = \mathbb{P}_i(T_0 < \infty)$, $h_0 = 1$. Then
\[
h_i = p_i h_{i+1} + q_i h_{i-1}
.\]
This gives
\[
	p_i (h_{i+1} - h_i) = q_i(h_{i} - h_{i-1})
.\]
We set $u_i = h_i - h_{i-1}$. Then
\[
u_{i+1} = \frac{q_i}{p_i} u_i = \cdots = \prod_{k = 1}^{i} \frac{q_k}{p_k}
,\]
with $u_1 = h_1 - 1$. Moreover, we have
\[
	h_i = \sum_{j = 1}^{i} (h_{j} - h_{j-1}) + 1 = 1 + \sum_{j = 1}^{i} u_j = 1 + u_1 + \sum_{j = 2}^{i} u_1 \prod_{k = 1}^{j-1} \frac{q_k}{p_k}
.\]
Hence
\[
	h_i = 1 + (h_1 - 1) + (h_1 - 1) \sum_{j = 2}^{i} \prod_{k = 1}^{j-1} \frac{q_k}{p_k}
.\]
We will let
\[
\lambda_j = \sum_{k = 0}^{j}\frac{q_k}{p_k}
,\]
where $\lambda_0 = 1$. Then
 \[
	 h_i = 1 - (1 - h_1) \sum_{j = 0}^{i-1} \lambda_j
.\]
We want $(h_i)$ to be the minimal non-negative solution, so
\[
	(1 - h_1) \leq \frac{1}{\sum_{j = 0}^{\infty} \lambda_j}
,\]
and
\[
h_1 = 1 - \frac{1}{\sum_{j = 0}^{\infty} \lambda_j}
,\]
by minimality. Thus if $\sum \lambda_j < \infty$, then
\[
h_i = \frac{\sum_{j = i}^{\infty} \lambda_j}{\sum_{j = 0}^{\infty} \lambda_j}
.\]
If the sum $\sum \lambda_j = \infty$, then $h_i = 1$.

\subsection{Mean Hitting Times}%
\label{sub:mean_hitting_times}

For $A \subset I$, $T_A = \inf\{n \geq 0 \mid X_n \in A\}$. Then $k^{A}_i = \mathbb{E}_i[T_A]$.

\begin{theorem}
	The vector $(k_i^{A} \mid i \in I)$ is the minimal non-negative solution to the system
	\[
	k_i^{A} =
	\begin{dcases}
		0 & i \in A, \\
		1 + \sum_{j \not \in A}P(i, j) k_j^{A} & i \in A
	\end{dcases}
	\]
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:} If $i \in A$, then $k_i^{A} = 0$. Assume $i \not \in A$. Then
\begin{align*}
	k_i^{A} &= \mathbb{E}_i[T_A] = \sum_{n = 0}^{\infty} \mathbb{P}_i (T_A > n) = \sum_{n = 0}^{\infty}\mathbb{P}_i(X_0 \not \in A, \ldots, X_n \not \ni A) \\
		&= 1 + \sum_{n = 1}^{\infty} \mathbb{P}_i(X_1 \not \in A, \ldots, X_n \not \in A) \\
		&= 1 + \sum_{n = 1}^{\infty} \sum_{j} \mathbb{P}_i(X_1 = j, X_1 \not \in A, \ldots, X_n \not \in A) \\
		&= 1 + \sum_{n = 1}^{\infty} \sum_{j} P(i, j) \mathbb{P}(X_1 \not \in A, \ldots, X_n \not \in A \mid X_1 = j) \\
		&= 1 + \sum_{n = 1}^{\infty} \sum_{j} P(i, j) \mathbb{P}_j(X_0 \not \in A, \ldots, X_{n-1} \not \in A) \\
		&= 1 + \sum_{j} P(i, j) \sum_{n = 0}^{\infty} \mathbb{P}_j(X_0 \not \in A, \ldots, X_n \not \in A) \\
		&= 1 + \sum_{j}P(i,j) k_j^{A} = 1 + \sum_{j \not \in A}P(i, j) k_{j}^{A}.
\end{align*}
\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
Now we show minimality. Let $(x_i)$ be another non-negative solution. The $x_i = 0$, $i \in A$. If $i \not \in A$,
\begin{align*}
	x_i &= 1 + \sum_{j \not \in A}P(i, j) x_j = 1 + \sum_{j \not \in A}P(i, j) + \sum_{j \not \in A}\sum_{k \not \in A}P(i, j) P(j, k) x_k \\
	    &=1 + \sum_{j_1 \not \in A}P(i, j_1) + \cdots + \sum_{j_1, \ldots, j_{n-1} \not \in A} P(i, j_1) \cdots P(j_{n-2}, j_{n-1}) + \cdots \\
	    &\geq 1 + \mathbb{P}_i(T_A > 1) + \cdots + \mathbb{P}_i(T_A > n).
\end{align*}
So $x_i \geq \mathbb{E}_i[T_A] = k_i^{A}$.

\end{adjustbox}

\subsection{Strong Markov Property}%
\label{sub:strong_markov_property}

We have proven that the past and the future are independent, as the simple Markov property. This says, for $m \in \mathbb{N}$, $i \in I$, and $X \sim \Mkv(\lambda, P0$, that conditional on $X_m = i$, $(X_{n+m})_{n \geq 0}$ is $\Mkv(\delta_i, P)$, and is independent of $X_0, \ldots, X_m$.

We look to replace the constant $m$ with a random variable.

\subsection{Stopping Times}%
\label{sub:stopping_times}

\begin{definition}
	A random variable $T : \Omega \to \{0, 1, \ldots\} \cup \{\infty\}$ is called a stopping time\index{stopping time} if the event $\{T = n\}$ depends on $X_0, \ldots, X_n$, for all $n \in \mathbb{N}$.
\end{definition}

For example, let $T_A = \inf\{n \geq 0 \mid X_n \in A\}$. Then $\{T_A = n\} = \{X_0 \not \in A, \ldots, X_{n-1} \not \in A, X_n \in A\}$. So the first hitting times are always stopping times.

However, $L_A = \sup\{n \leq 10 \mid X_n \in A\}$ is not a stopping time.

The strong Markov property is as follows:
\begin{proposition}\index{strong Markov property}
	Let $X$ be $\Mkv(\lambda, P)$ and let $T$ be a stopping time. Conditioning on $T < \infty$ and $X_T = i$, then $(X_{T + n})_{n \geq 0}$ is $\Mkv(\delta_i, P)$, and it is independent of $X_0, \ldots, X_T$.
\end{proposition}


\newpage

\printindex

\end{document}
