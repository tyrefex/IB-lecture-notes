\documentclass[12pt]{article}

\usepackage{ishn}
\usepackage{microtype}

\makeindex[intoc]

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{IB Markov Chains}

		\vspace{1em}
		\large
		Ishan Nath, Michaelmas 2022

		\vspace{1.5em}

		\Large

		Based on Lectures by Prof. Perla Sousi

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

\setcounter{section}{-1}

\section{Introduction}%
\label{sec:introduction}

\textbf{Markov chains} are random processes (sequence of random variables) that retain no memory of the past.

\subsection{History}%
\label{sub:history}

These were first studied by Markov in 1906. Before Markov, Poisson processes and branching processes were studied. The motivation was to extend the law of large numbers to a non-iid setting.

After Markov, Kolmogorov began studying continuous time Markov chains, also known as Markov processes. An important example is Brownian motion, which is a fundamental object in modern probability theory.

Markov chains are the simplest mathematical models for random phenomena evolving in time. They are \textbf{simple} in the sense they are amenable to tools from probability, analysis and combinatorics.

Applications of Markov chains include population growth, mathematical genetics, queueing networks and Monte Carlo simulation.

\subsection{PageRank Algorithm}%
\label{sub:pagerank_algorithm}\index{PageRank}

This is an algorithm used by Google Search to rank web pages. We model the web as a directed graph, $G = (V, E)$. Here, $V$ is the set of vertices, which are associated to the website, and $(i, j) \in E$ if $i$ contains a link to page $j$.

Let $L(i)$ be the number of outgoing edges from $i$, i.e. the outdegree, and let $|V| = n$. Then we define a set of probabilities
\[
	\hat{p}_{ij} =
\begin{cases}
	\frac{1}{L(i)} & \text{if } L(i) > 0, (i, j) \in E, \\
	\frac{1}{n} & \text{otherwise}.
\end{cases}
\]

Take $\alpha \in (0,1)$, then we define $p_{ij} = \alpha \hat{p}_{ij} + (1 - \alpha) \frac{1}{n}$. Consider a random surfer, who tosses a coin with bias $\alpha$, and either goes to $\hat p$, or chooses a website uniform at random.

We wish to find an invariant distribution $\pi = \pi P$. Then $\pi_{i}$ is the proportion of time spent at webpage $i$ by the surfer. We can then rank the pages by the values of $\pi_{i}$.

\newpage

\section{Formal Setup}%
\label{sec:formal_setup}

We begin with a state space $I$, which is either finite or countable, and a $\sigma$-algebra $(\Omega, \mathcal{F}, \mathbb{P})$.

\begin{definition}
	A stochastic process $(X_n)_{n \geq 0}$ is called a \textbf{Markov chain}\index{Markov chain} if for all $n \geq 0$, and $x_{0}, x_{1} ,\ldots, x_{n+1} \in I$,
	\[
		\mathbb{P}(X_{n+1} = x_{n+1} \mid X_{n} = x_{n}, \ldots, X_{0} = x_{0}) = \mathbb{P}(X_{n+1} = x_{n+1} \mid X_{n} = x_{n})
	.\]
	If $\mathbb{P}(X_{n+1} = y \mid X_{n} = x)$ is independent of $n$ for all $x, y$, then $X$ is called \textbf{time-homogeneous}\index{time-homogeneous}. Otherwise, it is \textbf{time-inhomogeneous}.

	For a time-homogeneous Markov chain, define $P(x, y) = \mathbb{P}(X_1 = y \mid X_0 = x)$. $P$ is called the \textbf{transition matrix}\index{transition matrix} of the Markov chain. We have
	\[
		\sum_{y \in I} P(x, y) = \sum_{y \in I} \mathbb{P}(X_1 = y \mid X_0 = x) = 1
	.\]
	Such a matrix is called a \textbf{stochastic matrix}\index{stochastic matrix}.
\end{definition}

\begin{definition}
	$(X_n)_{n \geq 0}$ with values in $I$ is called $\Mkv(\lambda, P)$ if $X_0 \sim \lambda$ and $(X_n)_{n \geq 0}$ is a Markov chain with transition matrix $P$.
\end{definition}

There are several equivalent definitions for Markov chains.

\begin{theorem}
	$X$ is $\Mkv(\lambda, P)$ if for all $n \geq 0$, $x_0, x_1, \ldots, x_n \in I$,
	\[
		\mathbb{P}(X_0 = x_0, \ldots, X_n = x_n) = \lambda(x_0)P(x_0,x_1) \cdots P(x_{n-1}, x_n)
	.\]
\end{theorem}

\begin{proofbox}
	If $X$ is $\Mkv(\lambda, P)$, then 
	\begin{align*}
		\mathbb{P}(X_n = x_n, \ldots, X_0 = x_0) &= \mathbb{P}(X_n = x_n \mid X_{n-1} = x_{n-1}, \ldots, X_0 = x_0) \times \cdots \\
							 & \times \mathbb{P}(X_1 = x_1 \mid X_0 = x_0) \mathbb{P}(X_0 = x_0) \\
							 &= \lambda(x_0)P(x_0,x_1)\cdots P(x_{n-1}, x_n).
	\end{align*}
	For the other direction, note for $n = 0$, we have $\mathbb{P}(X_0 = x_0) = \lambda(x_0)$, so $X_0 \sim \lambda$, and
	\begin{align*}
		\mathbb{P}(X_n = x_n \mid X_{n-1} = x_{n-1}, \ldots, X_0 = x_0) &= \frac{\mathbb{P}(X_n = x_n, \ldots, X_0 = x_0)}{\mathbb{P}(X_{n-1} = x_{n-1}, \ldots, X_0 = x_0)} \\
										&= P(x_{n-1}, x_n).
	\end{align*}
\end{proofbox}

\begin{definition}
	Let $i \in I$. The $\delta_{i}$-mass at $i$ is defined by
	\[
		\delta_{ij} = \mathbbm{1}(i = j) =
		\begin{cases}
			1 & \text{if } i = j, \\
			0 & \text{otherwise}.
		\end{cases}	
	\] 
\end{definition}

\begin{definition}
	Let $X_1, \ldots, X_{n}$ be discrete random variables with values in $I$. They are independent if for all $x_1, \ldots, x_n \in I$,
	\[
		\mathbb{P}(X_1 = x_1, \ldots, X_n = x_n) = \prod_{i = 1}^{n} \mathbb{P}(X_i = x_i)
	.\]
	Let $(X_n)_{n \geq 0}$ be a sequence of random variables in $I$.They are independent if for all $i_1 < i_2 < \cdots < i_k$, and for all $x_1, \ldots, x_k \in I$,
	\[
		\mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = i_k) = \prod_{j = 1}^{k} \mathbb{P}(X_{i_j} = x_j)
	.\]
	Let $(X_n)_{n \geq 0}$ and $(Y_n)_{n \geq 0}$ be two sequences. We say $X \perp Y$, or $X$ independent to $Y$,\index{independent sequences} if for all $k, m \in \mathbb{N}$, $i_1 < \cdots < i_k$, $j_1 < \cdots < j_m$, $x_1, \ldots, x_k, y_1, \ldots, y_m$,
	\begin{align*}
		\mathbb{P}(&X_{i_1} = x_1, \ldots, X_{i_k} = x_k, Y_{j_1} = y_1, \ldots, Y_{j_m} = y_m) \\
			   &= \mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k) \mathbb{P}(Y_{j_1} = y_1, \ldots, Y_{j_m} = y_m)
	.\end{align*}
\end{definition}

\subsection{Simple Markov Property}%
\label{sub:simple_markov_property}

\begin{theorem}[Simple Markov Property]\index{simple Markov property}
	Suppose $X$ is $\Mkv(\lambda, P)$ with values in $I$. Let $m \in \mathbb{N}$ and $i \in I$. Then conditional on $X_m = i$, the process $(X_{m+n})_{n \geq 0}$ is $\Mkv(\delta_i, P)$ and it is independent of $X_0, \ldots, X_m$.
\end{theorem}

\begin{proofbox}
	Let $x_0, \ldots, x_n \in I$. Then
\begin{align*}
	\mathbb{P}(X_m &= x_0, \ldots, X_{m+n} = x_n \mid X_m = i) \\
		       &= \delta_{ix_0} \frac{\mathbb{P}(X_m = x_0, \ldots, X_{m+n} = x_n)}{\mathbb{P}(X_m = i)}, \\
	\mathbb{P}(X_m &= x_0, \ldots, X_{m+n} = x_n) \\
		       &= \sum_{y_0,\ldots, y_{m-1}}\mathbb{P}(X_0 = y_0, \ldots, X_{m} = x_0, \ldots, X_{m+n} = x_0) \\
		       &= \sum_{y_0, \ldots, y_{m-1}} \lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, x_0) \cdots P(x_{n-1}, x_n) \\
		       &= P(x_0, x_1) \cdots P(x_{n-1}, x_n) \sum_{y_0, \ldots, y_{m-1}} \lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, x_0),
\end{align*}
\[
	\mathbb{P}(X_m = i) = \sum_{y_0, \ldots, y_{m-1}} \lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, i).
\]
Putting this together, we get the probability is
\[
	\delta_{ix_0}P(x_0, x_1)\cdots P(x_{n-1}, x_n) \implies \Mkv(\delta_i, P)
.\]
Now we show independence. Let $m \leq i_1 < \cdots < i_k$. Then,
\begin{align*}
	\mathbb{P}(X_{i_1} &= x_1, \ldots, X_{i_k} = x_k, X_0 = y_0, \ldots, X_m = y_m \mid X_{m} = i) \\
			   &= \frac{\mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k, X_0 = y_0, \ldots, X_m = y_m)}{\mathbb{P}(X_m = i)} \\
			   &= \frac{\lambda(y_0) P(y_0, y_1) \cdots P(y_{m-1}, y_m)}{\mathbb{P}(X_m = i)} \mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k \mid X_{m} = i) \\
			   &= \mathbb{P}(X_{i_1} = x_1, \ldots, X_{i_k} = x_k \mid X_{m} = i) \mathbb{P}(X_0 = y_0, \ldots \mid X_m = i).
\end{align*}
\end{proofbox}

Let $X \sim \Mkv(\lambda, P)$. How can we find $\mathbb{P}(X_n = x)$? Evaluating,
\begin{align*}
	\mathbb{P}(X_n = x) &= \sum_{x_0, \ldots, x_{n-1}}\mathbb{P}(X_0 = x_0, \ldots, X_n = x) \\
			    &= \sum_{x_0, \ldots, x_{n-1}} \lambda(x_0) P(x_0, x_1) \cdots P(x_{n-1}, x) = (\lambda P^{n})x.
\end{align*}
Here, $\lambda$ is a row vector, and $P^{n}$ is the $n$'th power of the transition matrix. By convention, $P^{0} = I$.

Consider the related problem of finding $\mathbb{P}(X_{n+m} = y \mid X_m = x)$. From the simple Markov property, $(X_{m+n})_{n \geq 0}$ is $\Mkv(\delta_{x}, P)$. So
\[
	\mathbb{P}(X_{n+m} = y \mid X_{m} = x) = (\delta_{x} P^{n})y = (P^{n})xy
.\]

\begin{exbox}
	Take the transition matrix
	\[
	P = 
	\begin{pmatrix}
		1 - \alpha & \alpha \\
		\beta & 1 - \beta
	\end{pmatrix}
	.\] 
	Then $p_{11}(n+1) = (1 - \alpha)p_{11}(n) + \beta p_{12}(n)$. Since $p_{11}(n) + p_{12}(n) = 1$, we get the general form
	\[
		p_{11}(n) =
		\begin{dcases}
			\frac{\alpha}{\alpha + \beta} + \frac{\alpha}{\alpha + \beta}(1 - \alpha - \beta)^{n} & \alpha + \beta > 0, \\
			1 & \alpha + \beta = 0.
		\end{dcases}	
	\]
\end{exbox}

Suppose $P$ is $k \times k$ stochastic, and let $\lambda_1, \ldots, \lambda_k$ be the eigenvalues of $P$.

If $\lambda_1, \ldots, \lambda_k$ are all distinct, then $P$ is diagonalisable, so we can write
\[
P = U
\begin{pmatrix}
	\lambda_1 & 0 & \cdots & 0 \\
	0 & \lambda_2 & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & \lambda_k
\end{pmatrix}
U^{-1}
.\]
Then we get
\[
P^{n} = U
\begin{pmatrix}
	\lambda_1^{n} & 0 & \cdots & 0 \\
	0 & \lambda_2^{n} & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & \lambda_k^{n}
\end{pmatrix}
.\]
Hence $p_{11}(n) = \alpha_1 \lambda_1^{n} + \cdots + \alpha_k \lambda_k^{n}$.

If one of the eigenvalues is complex, say $\lambda_{k-1}$, then also its conjugate is an eigenvalue. Say $\lambda_{k} = \overline{\lambda_{k-1}}$. If $\lambda_{k-1} = r e^{i \theta} = r \cos \theta + i r \sin \theta$, $\lambda_k = r \cos \theta - i r \sin \theta$, then we can write the general form as
\[
	p_{11}(n) = \alpha_1 \lambda_1^{n} + \cdots + \alpha_{k-2} \lambda_{k-2}^{n} + \alpha_{k-1} r^{n} \cos n \theta + \alpha_{k} r^{n} \sin n \theta
.\]

If an eigenvalue $\lambda$ has multiplicity $r$, then we must include the term $(a_{r-1}n^{r-1} + \cdots + a_1 n + a_0) \lambda^{n}$, by Jordan Normal Form.

\subsection{Communicating Classes}%
\label{sub:communicating_classes}

\begin{definition}
	$X$ is a Markov chain with matrix $P$ on $I$. Let $x, y \in I$. We say $x \to y$ ($x$ leads to $y$) if
	\[
	\mathbb{P}_x(X_n = y \text{ for some } n \geq 0\} > 0
	.\]
	We say that $x$ and $y$ communicate\index{communicate} and $x \leftrightarrow y$ if both $x \to y$ and $y \to x$.
\end{definition}

\begin{theorem}
	The following are equivalent:
	\begin{enumerate}[\normalfont(i)]
		\item $x \to y$;
		\item There exists a sequence $x = x_0, x_1, \ldots, x_k = y$ such that 
			\[P(x_0, x_1), \ldots, P(x_{k-1}, x_k) > 0;\]
		\item There exists $n \geq 0$ such that $P_{xy}(n) > 0$.
	\end{enumerate}	
\end{theorem}

\begin{proofbox}
We show (i) if and only if (iii). Note
\[
	\{X_n = y \text{ for some } n \geq 0 \} = \bigcup_{n \geq 0} \{X_n = y\}
.\]
If $x \to y$, then there exists $n \geq 0$ such that $\mathbb{P}_x(X_n = y) > 0$, so $P_{xy}(n) > 0$. If there exists $n \geq 0$ such that $P_x(X_n = y) > 0$, then $x \to y$.

Now we note (ii) iff (iii) as
\[
	\mathbb{P}_x(X_n = y) = \sum_{x_1, \ldots, x_{n-1}} P(x, x_1) \cdots P(x_{n-1}, y)
.\]
\end{proofbox}

\begin{corollary}
	$\leftrightarrow$ defines an equivalence class on $I$.
\end{corollary}

\begin{proofbox}
	$x \leftrightarrow x$ as $P_{xx}(0) = 1$, and $x \leftrightarrow y \iff y \leftrightarrow x$.

	Then transitivity follows from property (ii).
\end{proofbox}


\begin{definition}
	The equivalence classes induced by $\leftrightarrow$ on $I$ are called communicating classes\index{communicating classes}. We say that a class $C$ is closed\index{closed class} if whenever $x \in C$ and $x \to y$, then $y \in C$.

	A matrix $P$ is called irreducible\index{irreducible} if it has a single communicating class.

	A state $x$ is called absorbing\index{absorbing state} if $\{x\}$ is a closed class. Equivalently, if the Markov chain started from $x$, it would remain at $x$ forever.
\end{definition}

\subsection{Hitting Probabilities}%
\label{sub:hitting_probabilities}

\begin{definition}
	For $A \subset I$, we let $T_A : \Omega \to \mathbb{N} \cup \{\infty\}$. Then we define
	\[
		T_A(\omega) = \inf \{n \geq 0 : X_n(\omega) \in A\}
	.\]
	By convention, we take $\inf(\emptyset) = \infty$. Then $T_A$ is the first hitting time\index{first hitting time} of $A$.

	Denote $h_i^{A} = \mathbb{P}_i(T_A < \infty)$. Then $h^{A} : I \to [0, 1]$ is a vector of hitting probabilities. We can also define
	\[
		k^{A} : I \to \mathbb{R}_+ \cup \{\infty\}
	,\]
	as the mean hitting time. Then
	\[
		k_i^{A} = \mathbb{E}_i[T_A] = \sum_{n =  1}^{\infty }n \mathbb{P}_i(T_A = n)
	,\]
	if $\mathbb{P}_i(T_A = \infty) = 0$.
\end{definition}

\begin{theorem}
	Let $A \subset I$. The vector $(h_i^{A} : i \in A)$ is a solution to the linear system
	\[
	h_i^{A} =
	\begin{dcases}
		1 & i \in A, \\
		\sum_{j}P(i, j) h_j^{A} & i \not \in A.
	\end{dcases}
	\]
	The vector $(h_i^{A})$ is the minimal non-negative solution to this solution.
\end{theorem}

\begin{proofbox}
	Clearly, if $i \in A$, then $h_i^{A} = 1$. So assume $i \not \in A$. Then
\begin{align*}
	h_i^{A} &= \mathbb{P}_i(T_A < \infty) = \sum_{n = 1}^{\infty} \mathbb{P}_i(X_1 \not \in A, \ldots, X_{n-1} \not \in A, X_n \in A) \\
		&= \mathbb{P}_i(X_1 \in A) + \sum_{n = 2}^{\infty} \mathbb{P}_i(X_1 \not \in A, \ldots, X_n \in A) \\
		&= \mathbb{P}_i(X_1 \in A) + \sum_{n = 2}^{\infty} \sum_{j \not \in A} \mathbb{P}_i(X_1 = j, X_2 \not \in A, \ldots, X_n \in A) \\
		&= \mathbb{P}_i(X_1 \in A) + \sum_{n = 2}^{\infty} \sum_{j \not \in A}\mathbb{P}_i(X_2 \not \in A, \ldots, X_n \in A \mid X_0 = i, X_1 = j) P(i, j) \\
		&= \mathbb{P}_i(X_1 = A) + \sum_{n = 1}^{\infty} \sum_{j \not \in A}P(i, j) \mathbb{P}_j(X_1 \not \in A, \ldots, X_n \in A) \\
		&= \sum_{j \in A}P(i, j) h_j^{A} + \sum_{j \not \in A}P(i, j) h_j^{A} \\
		&= \sum_{j} P(i, j) h_j^{A}.
\end{align*}
Now we prove minimality. Let $(x_i)$ be another non-negative solution. We are required to show $h_i^{A} \leq x_i$. Assume $i \not \in A$. Then we know
\begin{align*}
	x_i &= \sum_{j}P(i, j)x_j \\
	x_i &= \sum_{j \in A}P(i, j) + \sum_{j \not \in A}P(i, j)x_j \\
	    &= \sum_{j \in A}P(i, j) + \sum_{j \not \in A}\sum_{k \in A}P(i, j)P(j, k) + \sum_{j \in A}\sum_{k \not \in A}P(i, j)P(j, k) x_k \\
	    &= \mathbb{P}_i(X_1 \in A) + \mathbb{P}_i(X_1 \not \in A, X_2 \in A) + \sum_{j \not \in A}\sum_{k \in A}P(i, j)P(j, k)x_k \\
	    &\geq \mathbb{P}_i(X_1 \in A) + \mathbb{P}_i(X_1 \not \in A, X_2 \in A) + \cdots + \mathbb{P}_i(X_1 \not \in A, \ldots, X_n \in A).
\end{align*}
Hence $x_i \geq \mathbb{P}_i(T_A \leq n)$, and since the union of these events is $\{T_A < \infty\}$, we get
\[
	x_i \geq \mathbb{P}_i(T_A < \infty) = h_i^{A}
.\] 
\end{proofbox}

\begin{exbox}
	Consider a simple random walk on $\mathbb{Z}_{+}$. We have a transition matrix $P(0, 1) = 1$, and $P(i, i+1) = p = 1 - P(i, i-1)$. Then we wish to find $h_i = \mathbb{P}_i(T_0 < \infty)$. We know $h_0 = 1$, and $h_i = p \cdot h_{i+1} + q h_{i-1}$. This gives
	\[
		h_i = a + b \left( \frac{q}{p} \right)^{i} = a + (1 - a) \left( \frac{q}{p} \right)^{i}
	.\]
	We assume $q > p$: to get the non-negative and minimal solution we need to take $a = 1$. Then $h_i = 1$ for all $i \geq 1$.

	Now assume $q < p$: We get $a = 0$, s $h_i = (q/p)^{i}$.

	If $p = q = 1/2$, we get $h_i = a + bi$, so by boundedness, $a = 1$, and $b = 0$. So $h_i = 1$ for all $i \geq 1$.
\end{exbox}

\subsection{Birth and Death chains}%
\label{sub:birth_and_death_chains}

The above example is almost a birth and death chain, with equal probability at each $i$. A \textit{birth and death chain}\index{birth and death chain} is a random walk on $\mathbb{Z}_{\geq 0}$, with transition probabilities $P(0, 0) = 1$, $P(i, i+1) = p_i$, $P(i, i-1) = q_i$.

We look at the hitting probabilities for a birth and death chain. Let $h_i = \mathbb{P}_i(T_0 < \infty)$, $h_0 = 1$. Then,
\[
h_i = p_i h_{i+1} + q_i h_{i-1}
.\]
This gives
\[
	p_i (h_{i+1} - h_i) = q_i(h_{i} - h_{i-1})
.\]
If we define $u_i = h_i - h_{i-1}$, then
\[
u_{i+1} = \frac{q_i}{p_i} u_i = \cdots = \prod_{k = 1}^{i} \frac{q_k}{p_k}
,\]
with $u_1 = h_1 - 1$. Moreover, we have
\[
	h_i = \sum_{j = 1}^{i} (h_{j} - h_{j-1}) + 1 = 1 + \sum_{j = 1}^{i} u_j = 1 + u_1 + \sum_{j = 2}^{i} u_1 \prod_{k = 1}^{j-1} \frac{q_k}{p_k}
,\]
\[
	\implies h_i = 1 + (h_1 - 1) + (h_1 - 1) \sum_{j = 2}^{i} \prod_{k = 1}^{j-1} \frac{q_k}{p_k}
.\]
We will let
\[
\lambda_j = \sum_{k = 0}^{j}\frac{q_k}{p_k}
,\]
where $\lambda_0 = 1$. Then
 \[
	 h_i = 1 - (1 - h_1) \sum_{j = 0}^{i-1} \lambda_j
.\]
We want $(h_i)$ to be the minimal non-negative solution, so
\[
	(1 - h_1) \leq \frac{1}{\sum_{j = 0}^{\infty} \lambda_j}, \qquad
h_1 = 1 - \frac{1}{\sum_{j = 0}^{\infty} \lambda_j}
,\]
by minimality. Thus if $\sum \lambda_j < \infty$, then
\[
h_i = \frac{\sum_{j = i}^{\infty} \lambda_j}{\sum_{j = 0}^{\infty} \lambda_j}
.\]
If the sum $\sum \lambda_j = \infty$, then $h_i = 1$.

\subsection{Mean Hitting Times}%
\label{sub:mean_hitting_times}

For $A \subset I$, $T_A = \inf\{n \geq 0 \mid X_n \in A\}$. Then $k^{A}_i = \mathbb{E}_i[T_A]$.

\begin{theorem}
	The vector $(k_i^{A} \mid i \in I)$ is the minimal non-negative solution to the system
	\[
	k_i^{A} =
	\begin{dcases}
		0 & i \in A, \\
		1 + \sum_{j \not \in A}P(i, j) k_j^{A} & i \in A
	\end{dcases}
	\]
\end{theorem}

\begin{proofbox}
	If $i \in A$, then $k_i^{A} = 0$. Assume $i \not \in A$. Then
\begin{align*}
	k_i^{A} &= \mathbb{E}_i[T_A] = \sum_{n = 0}^{\infty} \mathbb{P}_i (T_A > n) = \sum_{n = 0}^{\infty}\mathbb{P}_i(X_0 \not \in A, \ldots, X_n \not \ni A) \\
		&= 1 + \sum_{n = 1}^{\infty} \mathbb{P}_i(X_1 \not \in A, \ldots, X_n \not \in A) \\
		&= 1 + \sum_{n = 1}^{\infty} \sum_{j} \mathbb{P}_i(X_1 = j, X_1 \not \in A, \ldots, X_n \not \in A) \\
		&= 1 + \sum_{n = 1}^{\infty} \sum_{j} P(i, j) \mathbb{P}(X_1 \not \in A, \ldots, X_n \not \in A \mid X_1 = j) \\
		&= 1 + \sum_{n = 1}^{\infty} \sum_{j} P(i, j) \mathbb{P}_j(X_0 \not \in A, \ldots, X_{n-1} \not \in A) \\
		&= 1 + \sum_{j} P(i, j) \sum_{n = 0}^{\infty} \mathbb{P}_j(X_0 \not \in A, \ldots, X_n \not \in A) \\
		&= 1 + \sum_{j}P(i,j) k_j^{A} = 1 + \sum_{j \not \in A}P(i, j) k_{j}^{A}.
\end{align*}
Now we show minimality. Let $(x_i)$ be another non-negative solution. The $x_i = 0$, $i \in A$. If $i \not \in A$,
\begin{align*}
	x_i &= 1 + \sum_{j \not \in A}P(i, j) x_j = 1 + \sum_{j \not \in A}P(i, j) + \sum_{j \not \in A}\sum_{k \not \in A}P(i, j) P(j, k) x_k \\
	    &=1 + \sum_{j_1 \not \in A}P(i, j_1) + \cdots + \sum_{j_1, \ldots, j_{n-1} \not \in A} P(i, j_1) \cdots P(j_{n-2}, j_{n-1}) + \cdots \\
	    &\geq 1 + \mathbb{P}_i(T_A > 1) + \cdots + \mathbb{P}_i(T_A > n).
\end{align*}
So $x_i \geq \mathbb{E}_i[T_A] = k_i^{A}$.
\end{proofbox}

\subsection{Strong Markov Property}%
\label{sub:strong_markov_property}

We have proven that the past and the future are independent, as the simple Markov property. This says, for $m \in \mathbb{N}$, $i \in I$, and $X \sim \Mkv(\lambda, P)$, that conditional on $X_m = i$, $(X_{n+m})_{n \geq 0}$ is $\Mkv(\delta_i, P)$, and is independent of $X_0, \ldots, X_m$.

We look to replace the constant $m$ with a random variable.

\subsection{Stopping Times}%
\label{sub:stopping_times}

\begin{definition}
	A random variable $T : \Omega \to \{0, 1, \ldots\} \cup \{\infty\}$ is called a stopping time\index{stopping time} if the event $\{T = n\}$ depends on $X_0, \ldots, X_n$, for all $n \in \mathbb{N}$.
\end{definition}

For example, let $T_A = \inf\{n \geq 0 \mid X_n \in A\}$. Then $\{T_A = n\} = \{X_0 \not \in A, \ldots, X_{n-1} \not \in A, X_n \in A\}$. So the first hitting times are always stopping times.

However, $L_A = \sup\{n \leq 10 \mid X_n \in A\}$ is not a stopping time.

The strong Markov property is as follows:
\begin{proposition}\index{strong Markov property}
	Let $X$ be $\Mkv(\lambda, P)$ and let $T$ be a stopping time. Conditioning on $T < \infty$ and $X_T = i$, then $(X_{T + n})_{n \geq 0}$ is $\Mkv(\delta_i, P)$, and it is independent of $X_0, \ldots, X_T$.
\end{proposition}

\begin{proofbox}
	Take $x_0, \ldots, x_n \in I$, and $w \in \bigcup I^{k}$. Then we will show
\begin{align*}
	\mathbb{P}(X_T &= x_0, \ldots, X_{T+n} = x_n, (X_0, \ldots, X_T) = \omega \mid T < \infty, X_T = i) \\
		       &= \delta_{ix_0}P(x_0, x_1)\cdots P(x_{n-1}, x_n) \mathbb{P}((X_0, \ldots, X_T) = \omega \mid T< \infty, X_T = i).
\end{align*}
This proves both statements. Set $\omega$ to have length $k$. Then
\begin{align*}
	\mathbb{P}(X_k =& x_0, \ldots, X_{k+n} = x_n, (X_0, \ldots, X_k) = \omega, T = k \mid T < \infty, X_T = i) \\
	= & \frac{\mathbb{P}(X_k = x_0, \ldots, X_{k+n} = x_n, (X_0, \ldots, X_k) = \omega, T = k, X_k = i)}{\mathbb{P}(T < \infty, X_T = i)} \\
	= & \mathbb{P}(X_k = x_0, \ldots, X_{k+n} = x_n \mid (X_0, \ldots, X_k) = \omega, T = k, X_k = i)\\
	  & \times \frac{\mathbb{P}((X_0, \ldots, X_k) = \omega, T = k, X_k = i)}{\mathbb{P}(T < \infty, X_T = i)} \\
	= &\mathbb{P}(X_k = x_0, \ldots, X_{k+n} = x_n \mid X_k = i) \\
	  & \times \mathbb{P}((X_0, \ldots, X_k) = \omega, T = k \mid T < \infty, X_T = i) \\
	= & \delta_{ix_0}P(x_0, x_1) \cdots P(x_{n-1}, x_n) \mathbb{P}((X_0, \ldots, X_T) = \omega \mid T < \infty, X_T = i).
\end{align*}
This proves the Strong Markov property.
\end{proofbox}

\begin{exbox}
	Consider a Markov chain with $P(0, 1) = 1$, and $P(i, i+1) = P(i, i-1) = 1/2$. Let $T_0 = \inf\{n \geq 0 \mid X_n = 0\}$, and let $h_i = \mathbb{P}_i(T_0 < \infty)$.

	We know that $h_0 = 1$. We can condition to find $h_1 = 1/2 + h_2/2$.

	We can use more knowledge of the Markov chain to find $h_2$. Notice that
	\begin{align*}
		h_2 &= \mathbb{P}_2(T_0 < \infty) = \mathbb{P}_2(T_1 < \infty, T_0 < \infty) \\
		    &= \mathbb{P}_2(T_0 < \infty \mid T_1 < \infty) \mathbb{P}_2(T_1 < \infty).
	\end{align*}
	Then conditional on $T_1 < \infty$, by the strong Markov property, $X_{T_1 + n}$ is $\Mkv(\delta_1, P)$. So we can express $T_0 = T_1 + \tilde T_0$, where $\tilde T_0$ is independent of $T_1$ and has the same law as $T_0$ under $\mathbb{P}_1$. Hence
	\[
		\mathbb{P}_2(T_0 < \infty \mid T_1 < \infty) = \mathbb{P}_2(\tilde T_0 + T_1 < \infty \mid T_1 < \infty) = \mathbb{P}_1(T_0 < \infty) = h_1
	.\]
	This gives $h_2 = h_1^2$, so $h_1 = 1/2 +h_1^2/2$ implies $h_1 = 1$.
\end{exbox}

\newpage

\section{Transience and Recurrence}%
\label{sec:transience_and_recurrence}

\begin{definition}
	A state $i$ is called recurrent\index{recurrent} if
	\[
		\mathbb{P}_i(X_n = i \text{ for infinitely many } n) = 1
	.\]
	A state $i$ is called transient\index{transient} if
	\[
		\mathbb{P}_i(X_n = i \text{ for infinitely many } n) = 0
	.\]
\end{definition}

Define the total number of visits $V_i$ as
\[
	V_i = \sum_{l = 0}^{\infty} \mathbbm{1}(X_l = i)
.\]
Then by definition, we known $\mathbb{P}_i(V_i > 0) = 1$. Moreover, we can write $\mathbb{P}_i(V_i > 1) = \mathbb{P}_i(T_i^{(1)} < \infty)$, where $T_i^{(1)}$ is the first return time.

Using the strong Markov property, we can then write $\mathbb{P}_i(V_i > 2) = \mathbb{P}_i(T_i^{(1)} < \infty)^2$. Indeed, let $T_i^{(0)} = 0$, and for $k \geq 1$, define 
\[
	T_i^{(k)} = \inf\{n > T_i^{(k-1)} \mid X_n = i\}
.\]
This is the $k$-th return time to $i$\index{return time}. Define
\[
	f_i = \mathbb{P}_i(T_i^{(1)} < \infty)
.\]

\begin{lemma}
	For all $r \in \mathbb{N}$,
	\[
		\mathbb{P}_i(V_i > r) = f_i^{r}
	.\]
	Thus $V_i$ has geometric distribution.
\end{lemma}

\begin{proofbox}
	$r = 0$ is trivially true. Suppose it is true for $r \leq k$. We will prove it for $k + 1$. Indeed,
\begin{align*}
	\mathbb{P}_i(V_i > k+1) &= \mathbb{P}_i(T_i^{(k+1)} < \infty) = \mathbb{P}_i(T_i^{(k+1)}< \infty, T_i^{(k)} < \infty) \\
				&= \mathbb{P}_i(T_i^{(k+1)} < \infty \mid T_i^{(k)} < \infty) \mathbb{P}_i(T_i^{(k)} < \infty).
\end{align*}
By induction, we have $\mathbb{P}_i(T_i^{(k)} < \infty) = \mathbb{P}_i(V_i > k) = f_i^{k}$.

Moreover, the successive return times to $i$ are stopping times, so conditional on $T_i^{(k)} < \infty$, we have $(X_{T_i^{(k)} + n})$ is $\Mkv(\delta_i, P)$, and is independent of $X_0, \ldots, X_{T_i^{(k)}}$ by the strong Markov property. Hence,
\[
	\mathbb{P}_i(T_i^{(k+1)} < \infty \mid T_i^{(k)} < \infty) = \mathbb{P}_i(T_i^{(1)} < \infty) = f_i
.\]
This finishes the proof.
\end{proofbox}

\begin{theorem}
	\begin{enumerate}[\normalfont(a)]
		\item[]
		\item If $f_i = 1$, then $i$ is recurrent and
			\[
				\sum_{n \geq 0} p_{ii}(n) = \infty
			.\]
		\item If $f_i < 1$, then $i$ is transient and
			\[
				\sum_{n \geq 0} p_{ii}(n) < \infty
			.\]
	\end{enumerate}
\end{theorem}

\begin{proofbox}
	Note that
\[
	\mathbb{E}_i[V_i] = \mathbb{E}_i\Biggl[\sum_{l = 0}^{\infty} \mathbbm{1}(X_l = i) \Biggr] = \sum_{l = 0}^{\infty} p_{ii}(l)
.\]
\begin{enumerate}[(a)]
	\item If $f_i = 1$, then by our lemma, $\mathbb{P}_i(V_i = \infty) = 1$. Hence $i$ is recurrent, so
		\[
			\mathbb{E}_i[V_i] = \infty \implies \sum_{n \geq 0} p_{ii}(n) = \infty
		.\]
	\item If $f_i < 1$, from our lemma,
		\[
			\mathbb{E}_i[V_i] = \frac{1}{1 - f_i} < \infty \implies \sum_{n \geq 0} p_{ii}(n) < \infty
		,\]
		which implies that $\mathbb{P}_i(V_i < \infty) = 1$, so $i$ is transient.
\end{enumerate}
\end{proofbox}

\subsection{Transient and Recurrent Classes}%
\label{sub:transient_and_recurrent_classes}

\begin{theorem}
	If $x \leftrightarrow y$, then $x$ and $y$ are either both recurrent or both transient.
\end{theorem}

\begin{proofbox}
	We will show if $x$ is recurrent, then $y$ is as well. Note if $x \leftrightarrow y$, then there exist $m, r > 0$ such that $p_{xy}(m) > 0$, and $p_{yx}(r) > 0$. Hence
	\[
		p_{yy}(n + m + r) \geq p_{yx}(r)p_{xx}(n)p_{xy}(m),
	\]
	so
	\[
		\sum_{n \geq 0}p_{yy}(n+m+r) \geq p_{yx}(r)p_{xy}(m) \sum_{n \geq 0}p_{xx}(n) = \infty
	,\]
	as $x$ is recurrent. Hence $y$ is also recurrent.
\end{proofbox}

\begin{corollary}
	All states in a communicating class are either all recurrent or all transient.
\end{corollary}

\begin{theorem}
	If $C$ is a recurrent communicating class, then $C$ is closed.
\end{theorem}

\begin{proofbox} Let $x \in C$, and $x \to y$ but $y \not \in C$. Since $x \to y$, there exist some $m > 0$ such that $p_{xy}(m) > 0$. But then
	\[
		\mathbb{P}_x(V_x < \infty) \geq p_{xy}(m) > 0
	.\]
	So this shows that $x$ is transient.
\end{proofbox}

\begin{theorem}
	A finite closed class is recurrent.
\end{theorem}

\begin{proofbox}
	Let $x \in C$. Since $C$ is finite, there exists $y \in C$ such that
	\[
		\mathbb{P}_x(X_n = y \text{ for infinitely many } n) > 0
	\]
	by the pigeonhole principle. Hence
	\begin{align*}
		\mathbb{P}_y(X_n &= y \text{ for infinitely many } n) \\
				 &\geq \mathbb{P}_y(X_m = x, X_n = y \text{ for infinitely many } n \geq m) \\
								     &= \mathbb{P}_y (X_n = y \text{ for infinitely many } n \geq m \mid X_m = x)\mathbb{P}_y(X_m = x) \\
								     &= \mathbb{P}_x(X_n = y \text{ for infinitely many } n) p_{yx}(m) > 0.
	\end{align*}
	So $\mathbb{P}_y(X_n = y \text{ for infinitely many } n) > 0$, so $y$ is recurrent.
\end{proofbox}

\begin{theorem}
	If $P$ is irreducible and recurrent, then for all $x, y$,
	\[
		\mathbb{P}_x(T_y < \infty) = 1
	.\]
\end{theorem}

\begin{proofbox}
\begin{align*}
	\mathbb{P}_x(X_n &= y \text{ infinitely many times}) \\
			 &= \mathbb{P}_x(T_y < \infty, X_n = y \text{ for infinitely many } n \geq T_y) \\
							    &= \mathbb{P}_x(X_n = y \text{ for infinitely many } n \geq T_y \mid T_y < \infty) \mathbb{P}_x(T_y < \infty) \\
							    &= \mathbb{P}_y(X_n = y \text{ for infinitely many } n) \mathbb{P}_x(T_y < \infty) = \mathbb{P}_x(T_y < \infty).
\end{align*}
Suppose that $\mathbb{P}_x(T_y < \infty) < 1$, so $\mathbb{P}_x(T_y = \infty) > 0$. Then
\begin{align*}
	\mathbb{P}_y(V_y < \infty) &\geq \mathbb{P}_y(X_m = x, \tilde T_y = \infty) \\
				   &=\mathbb{P}_y(\tilde T_y = \infty \mid X_m = x) \mathbb{P}_y(X_m = x) \\
				   &= \mathbb{P}_x(T_y = \infty) p_{yx}(m) > 0.
\end{align*}
This implies $y$ is transient, a contradiction.
\end{proofbox}

\subsection{Simple Random Walks on \texorpdfstring{$\mathbb{Z}^{d}$}{Z\^d}}%
\label{sub:simple_random_walks_on_zd}

\begin{definition}
	A simple random walk\index{simple random walk} on $\mathbb{Z}^{d}$ is a Markov chain with transition matrix
	\[
		P(x, x+e_i) = P(x, x-e_i) = \frac{1}{2d}
	.\]
\end{definition}

\begin{theorem}[P\'{o}lya]
	A simple random walk is recurrent when $d \leq 2$ and it is transient when $d \geq 3$.
\end{theorem}

\begin{proofbox}
	We first prove recurrence when $d = 1$. This is a simple random walk on $\mathbb{Z}$. Since this is irreducible, it is enough to show $0$ is recurrent, that is,
	\[
		\sum_{n \geq 0}p_{00}(n) = \infty
	.\]
	Note $p_{00}(n) = \mathbb{P}_0(X_n = 0)$. Note $n$ must be even for this to be possible. We can calculate
	\[
		\mathbb{P}_0(X_{2n} = 0) = \binom{2n}{n} \cdot \biggl( \frac{1}{2} \biggr)^{2n} = \frac{(2n)!}{n! \cdot n!} \cdot \frac{1}{2^{2n}} \sim \frac{1}{\sqrt{\pi n}}
	,\]
	where we use Stirling's formula. Hence, since this sum diverges, the simple random walk on $\mathbb{Z}$ is recurrent.

	Consider when $P(i, i+1) = p$, $P(i, i-1) = q$, where $p \neq q$, $p + q = 1$. We show this is not recurrent. Indeed,
	\[
		\mathbb{P}_0(X_{2n} = 0) = \binom{2n}{n} p^{n}q^{n} \sim \frac{(4pq)^{n}}{\sqrt{\pi n}}
	.\]
	If $p \neq q$, then $4pq < 1$, so this sum converges as it is exponential, implying that the walk is transient.

	For $d = 2$, we project the random walk onto the lines $y = x$ and $y = -x$. Then we prove that these are independent random walks on $\sqrt{2} \mathbb{Z}$.

	Define a function $f : \mathbb{Z}^2 \to \mathbb{R}^2$ by
	\[
		f(x, y) = \biggl( \frac{x + y}{\sqrt 2}, \frac{x - y}{\sqrt 2} \biggr)
	.\]
	Then for a simple random walk $(X_n)$ on $\mathbb{Z}^2$, let
	\[
		f(X_n) = (X_n^{+}, X_n^{-})
	.\]

\begin{theorem}
	$(X_{n}^{+}), (X_{n}^{-})$ are two independent simple random walks on $\mathbb{Z}/\sqrt 2$.
\end{theorem}

Indeed, let $(\xi_i)$ be an iid sequence, where
\[
	\mathbb{P}(\xi_i = (0, 1)) = \mathbb{P}(\xi_i = (1, 0)) = \mathbb{P}(\xi_i = (0, -1)) = \mathbb{P}(\xi_i = (-1, 0)) = \frac{1}{4}
.\]
Let $\xi_i = (\xi_i^{1}, \xi_i^{2})$, and define $X_n$ as the partial sums of the $\xi_i$. Then
\[
	f(X_n) = \Biggl( \sum_{i = 1}^{n} \frac{(\xi_i^{1} + \xi_i^{2})}{\sqrt 2}, \sum_{i = 1}^{n} \frac{(\xi_i^{1} - \xi_i^{2})}{\sqrt 2} \Biggr) = (X_{n}^{+}, X_{n}^{-})
.\]
It is easy to see that $(X_n^{+}), (X_{n}^{-})$ are simple random walks on $\mathbb{Z}/\sqrt 2$. To show they are independent, it is enough to check that $\xi_i^{1} + \xi_i^{2}$ is independent of $\xi_i^{1} - \xi_i^{2}$. This can be done by calculating all possiblities.

Hence, applying this, we get
\[
	\mathbb{P}_0(X_{2n} = 0) = \mathbb{P}_0(X_{2n}^{+} = 0, X_{2n}^{-} = 0) \sim \frac{1}{\pi n}
.\]
This sum diverges, hence $\mathbb{Z}^2$ is recurrent.

Finally, we prove $\mathbb{Z}^3$ is transient by showing $\sum_n p_{00}(n) < \infty$. In order for the walk to be back at $0$ after $2n$ steps is it to make:
\begin{itemize}
	\item $i$ steps to the right, $i$ steps to the left,
	\item $j$ steps north, $j$ steps south,
	\item $k$ steps east, $k$ steps west,
\end{itemize}
for $i+j+k = n$. Hence we can write
\begin{align*}
	p_{00}(2n) &= \sum_{\substack{i, j, k \geq 0 \\ i + j + k = n}} \binom{2n}{i,i,j,j,k,k} \biggl(\frac{1}{6}\biggr)^{2n} \\
		   &= \binom{2n}{n} \biggl( \frac{1}{2} \biggr)^{2n} \sum_{\substack{i, j, k \geq 0 \\i + j + k = n}} \binom{n}{i,j,k}^2 \biggl(\frac{1}{3}\biggr)^{2n}.
\end{align*}
By a simple combinatorial argument, we get
\[
	\sum_{\substack{i, j, k \geq 0 \\i + j + k = n}}\binom{n}{i,j,k} \biggl(\frac{1}{3}\biggr)^{n} = 1
.\]
We now prove a lemma. Let $n = 3m$. Then our claim is
\[
	\binom{n}{i,j,k} \leq \binom{n}{m,m,m}
.\]
Indeed, if the maximum is attained at $i, j, k$, then $i \leq j + 1$, as
\[
	\binom{n}{i,j,k} \geq \binom{n}{i-1,j+1,k} \implies i!j! \leq (i-1)!(j+1)! \implies i \leq j + 1
.\]
Since this holds for any pair in $(i,j,k)$, we have $(i,j,k) = (m,m,m)$. Hence, for $n = 3m$, we can bound
\[
	p_{00}(2n) \leq \binom{2n}{n} \biggl(\frac{1}{2}\biggr)^{2n} \biggl(\frac{1}{3}\biggr)^{n} \binom{n}{m,m,m} \leq \frac{A}{n^{3/2}}
,\]
for some $A$, by Stirling's formula. So $\sum_{m} p_{00}(6m) < \infty$. But now
\[
	p_{00}(6m) \geq p_{00}(6m - 2) \biggl(\frac{1}{6}\biggr)^2, \quad p_{00}(6m) \geq p_{00}(6m - 4) \biggl(\frac{1}{6}\biggr)^{4}
.\]
So $\sum_{n} p_{00}(2n) < \infty$, giving transience.
\end{proofbox}

\newpage

\section{Invariant Distributions}%
\label{sec:invariant_distributions}

\subsection{Probability Distributions}%
\label{sub:probability_distributions}

\begin{definition}
	Let $I$ be a discrete set. Then $\lambda = (\lambda_i \mid i \in I)$ is a probability distribution if $\lambda_i \geq 0$ and $\sum_{i \in I}\lambda_i = 1$.\index{probability distribution}
\end{definition}

\begin{exbox}
	Consider the Markov chain with transition probability
	\[
	P =
	\begin{pmatrix}
		1/2 & 1/2 \\
		1/2 & 1/2
	\end{pmatrix}
	.\]
	Then by looking at $P^{n}$, we can show that $p_{11}(n) \to 1/2$ as $n \to \infty$. So the Markov chain will converge to $(1/2, 1/2)$.
\end{exbox}

We want to find a probability distribution $\pi$ such that if $X_0 \sim \pi$, then $X_n \sim \pi$ for all $n$. Then
\begin{align*}
	\pi(j) &= \mathbb{P}(X_1 = j) = \sum_{i} \mathbb{P}(X_0 = i, X_1 = j) \\
	       &= \sum_{i} \mathbb{P}(X_1 = j \mid X_0 = i)\mathbb{P}(X_0 = i) = \sum_{i}P(i, j) \pi(i).
\end{align*}
Hence $\pi(j) = \sum_{i} \pi(i) P(i, j)$, or $\pi = \pi P$, where $\pi$ is a row vector.

\begin{definition}
	A probability distribution $\pi$ is called invariant (or stationary or equilibrium)\index{invariant}\index{stationary} of $\pi = \pi P$.
\end{definition}

\begin{theorem}
	Let $\pi$ be invariant and $X_0 \sim \pi$. Then $X_n \sim \pi$.
\end{theorem}

\begin{proofbox} 
	We proceed by induction. Our base case $n = 0$ is given to us. Now assume $X_{n} \sim \pi$. Then
	\begin{align*}
		\mathbb{P}(X_{n+1} = j) &= \sum_{i} \mathbb{P}(X_{n+1} = j, X_n = i) \\
					&= \sum_{i}\mathbb{P}(X_{n+1} = j \mid X_n = i) \mathbb{P}(X_n = i) \\
					&= \sum_{i} P(i, j) \pi(i) = \pi(j).
	\end{align*}
\end{proofbox}

\begin{theorem}
	Let $I$ be a finite set and suppose that there exists $i \in I$ such that $p_{ij}(n) \to \pi(j)$ as $n \to \infty$. Then $\pi = (\pi(i) \mid i \in I)$ is an invariant distribution.
\end{theorem}

\begin{proofbox}
	\[
		\sum_{j \in I}\pi_j = \sum_{j \in I}\lim_{n \to \infty}p_{ij}(n) = \lim_{n \to \infty}\sum_{j \in I}p_{ij}(n) = 1,
	\]
	so $\pi$ is a probability distribution. Now note
	\begin{align*}
		\pi_j &= \lim_{n \to \infty}p_{ij}(n) = \lim_{n \to \infty} \sum_{k \in I}p_{ik}(n-1) P(k, j)) \\
		    &= \sum_{k \in I}\lim_{n \to \infty}p_{ik}(n-1) P(k, j) = \sum_{k \in I}\pi_k P(k, j),
	\end{align*}
	so $\pi = \pi P$.
\end{proofbox}
\begin{remark}
	$I$ is finite is essential. Consider a walk on $\mathbb{Z}$, with $P(i, i+1) = 1$. Then $p_{0i} \to 0$ for all $i$.

	Since $P$ is a stochastic matrix, $1$ is always an eigenvalue. If $P$ is irreducible on a finite state sequence, then the Perron-Frobenius theorem ensures the existence of an invariant distribution.
\end{remark}

\subsection{Invariant Measures}%
\label{sub:invariant_measures}

\begin{definition}
	For $k \in I$, define $T_k = \inf\{n \geq 1 \mid X_n = k\}$ be the first return time to $k$. Then for every state $i$, define
	\[
		\nu_k(i) = \mathbb{E}_k\Biggl[ \sum_{\ell = 0}^{T_k - i} \mathbbm{1}(X_{\ell} = i) \Biggr]
	,\]
	so $\nu_k(i)$ is the expected number of visits to $i$ during an excursion from $k$. Thus $\nu_k$ is a measure on $I$.
\end{definition}

\begin{theorem}
	If $P$ is irreducible and recurrent, then $\nu_k$ is an invariant measure satisfying $0 < \nu_k(i) < \infty$, and $\nu_k(k) = 1$.
\end{theorem}

\begin{proofbox}
	Clearly $\nu_k(k) = 1$. Let $i \in I$. We will prove invariance, so $\nu_k(i) = \sum P(j,i) \nu_k(j)$. By recurrence, we get that $T_k < \infty$ with probability $1$, and $X_{T_k} = k$. So,
	\begin{align*}
		\nu_k(i) &= \mathbb{E}_k\Biggl[\sum_{\ell = 1}^{T_k}\mathbbm{1}(X_{\ell} = i)\Biggr] = \mathbb{E}_k\Biggl[\sum_{\ell  1}^{\infty} \mathbbm{1}(X_{\ell} = 1) \mathbbm{1}(T_k \geq \ell) \Biggr] \\
			 &= \sum_{\ell = 1}^{\infty} \mathbb{P}_k(X_{\ell} = i, T_k \geq l) = \sum_{\ell = 1}^{\infty} \sum_{j} \mathbb{P}_k(X_{\ell} = i, X_{\ell - 1} = j, T_{k} \geq \ell) \\
			 &= \sum_{\ell = 1}^{\infty} \sum_{j} \mathbb{P}_k(X_{\ell} = i \mid X_{\ell - 1} = j, T_{k} \geq l)\mathbb{P}_k(X_{\ell - 1}=j \mid T_{k} \geq \ell).
	\end{align*}
	Applying the Strong Markov property,
	\[
		\mathbb{P}_k(X_{\ell} = i \mid X_{\ell - 1} = j, T_k \geq l) = \mathbb{P}_k(X_{\ell} = i \mid X_{\ell - 1} = k) = P(j,i)
	.\]
	So
	\begin{align*}
		\nu_k(i) &= \sum_{\ell = 1}^{\infty} \sum_{j} P(j, i)\mathbb{P}_k(X_{\ell - 1} = j, T_{k} \geq \ell) \\
			 &= \sum_{j} P(j, i) \mathbb{E}_k\Biggl[\sum_{\ell = 1}^{\infty} \mathbbm{1}(X_{\ell - 1} = j, T_k \geq \ell) \Biggr] \\
			 &= \sum_{j} P(j, i) \nu_k(j).
	\end{align*}
	Hence $\nu_k$ is invariant. Now we show $\nu_k(i) > 0$. Since $\nu_k = \nu_k P^{m}$, we have
	\[
		\nu_k(i) \geq \nu_k(k) p_{ki}(m) = p_{ki}(m)
	.\]
	By irreducibility, there exists $m$ such that $p_{ki}(m) > 0$, so $\nu_k(i) > 0$. Now we show $\nu_k(i) < \infty$. Indeed,
	\[
		1 = \nu_k(k) \geq \nu_k(i) p_{ik}(m)
	.\]
	Take $n$ such that $p_{ik}(n) > 0$. Then we get
	\[
		\nu_k(i) \leq \frac{1}{p_{ik}(n)} < \infty
	.\]
\end{proofbox}

\begin{theorem}
	If $P$ is irreducible and $\lambda$ is an invariant measure satisfying $\lambda_k = 1$, then $\lambda \geq \nu_k$.
	
	If $P$ is also recurrent, then $\lambda = \nu_k$.
\end{theorem}

\begin{proofbox}
	We have $\lambda_i \geq 0$ for all $i$. Then
	\begin{align*}
		\lambda_i &= \sum_{j} \lambda_j P(j, i) = P(k, i) + \sum_{j_1 \neq k} P(j_1, i) \lambda_{j_1} \\
			  &= P(k,1) + \sum_{j_1 \neq k}P(k, j_1)P(j_1, i) + \sum_{\substack{j_1 \neq k, \\j_2 \neq k}} P(j_2, j_1)P(j_1, i) \lambda_{j_2} \\
			  &= P(k,i) + \sum_{k_1 \neq k}P(k, j_1)P(j_1, i) + \cdots \\
			  &\quad + \sum_{j_1, \ldots, j_{n-1} \neq k} P(k, j_{n-1} \cdots P(j_1,i) + \sum_{j_1, \ldots, j_{n} \neq k}P(j_n, j_{n-1}) \cdots P(j_1, i) \lambda_{j_n}.
	\end{align*}
	Using the fact $\lambda_{j_n} \geq 0$, we have
	\begin{align*}
		\lambda_i &\geq \mathbb{P}_k(X_1 = i, T_k \geq 2) + \mathbb{P}_k(X_2 = i, T_k \geq 3) \\
			  & \qquad + \cdots + \mathbb{P}_k(X_n = i, T_k \geq n+1), \\
		\lambda_i &\geq \mathbb{E}_k\Biggl[\sum_{\ell = 1}^{n}\mathbbm{1}(X_{\ell} = i, T_k \geq \ell + 1) \Biggr] \\
			  &= \sum_{\ell = 0}^{n} \mathbb{E}_k[\mathbbm{1}(X_{\ell} = i, \ell \leq T_{k}-1)].
	\end{align*}
	Taking $n \to \infty$, we get that $\lambda_i \geq \nu_k(i)$.

	If $P$ is recurrent, then $\nu_k$ is an invariant measure with $\nu_k(k) = 1$. Let $\mu_i = \lambda_i - \nu_k(i)$, an invariant measure with $\mu_i \geq 0$ and $\mu_k = 0$. Then we want to show $\mu_i = 0$ for all $i$. Let $i \in I$. Then,
	\[
		0 = \mu_k = \sum_{j} \mu_j P^{m}(j, k) \implies \mu_k \geq \mu_i P^{m}(i,k)
	.\]
	Taking $m$ such that $P_m(i, k) > 0$, we have $\mu_i = 0$.
\end{proofbox}

\begin{remark}
	If $P$ is irreducible and recurrent, then all invariant measures are unique up to multiplicative factors.
\end{remark}

Now we want to find out when we can get an invariant distribution $\pi = \pi P$ with $\sum \pi_i = 1$.

For $P$ irreducible and recurrent, by uniqueness, we can get an invariant distribution which is unique. If $\sum \nu_k(i) < \infty$, then we can find an invariant distribution
\[
	\pi_i = \frac{\nu_k(i)}{\sum_{j} \nu_k(j)}
.\]

Thus we are interested in when this sum is finite. Note
\begin{align*}
	\sum_{i \in I}\nu_k(i) &= \sum_{i \in I}\mathbb{E}_k\Biggl[\sum_{\ell = 0}^{T_k - 1}\mathbbm{1}(X_{\ell} = i) \Biggr] = \mathbb{E}_k\Biggl[\sum_{\ell = 0}^{T_k - 1}\sum_{i \in I} \mathbbm{1}(X_{\ell = i})\Biggr] \\
			       &= \mathbb{E}_k[T_k].
\end{align*}
So if $\mathbb{E}_k[T_k] < \infty$, then we can normalise.

\subsection{Positive and Null Recurrence}%
\label{sub:positive_and_null_recurrence}

\begin{definition}
	For $P$ irreducible and recurrent, let $T_k = \inf\{n \geq 1 \mid X_n = k\}$. Then $P$ recurrent implies $\mathbb{P}_k(T_k < \infty) = 1$.

	We say $k$ is \textit{positive recurrent}\index{positive recurrent} if $\mathbb{E}_k[T_k] < \infty$. Otherwise, we say $k$ is \textit{null recurrent}\index{null recurrent}.
\end{definition}

If $k$ is positive recurrent, then
\[
	\pi_j = \frac{\nu_k(k)}{\mathbb{E}_k[T_k]} = \frac{1}{\mathbb{E}_k[T_k]}
.\]

\begin{theorem}
	Let $P$ be an irreducible matrix. Then the following are equivalent:
	\begin{enumerate}[\normalfont(i)]
		\item All states are positive recurrent;
		\item Some state is positive recurrent;
		\item There exists an invariant distribution $\pi_i$.
	\end{enumerate}
	If any of the above holds, then $\pi_k = (\mathbb{E}_k[T_k])^{-1}$ exists and is an invariant distribution.
\end{theorem}

\begin{proofbox}
	Clearly (i) $\implies$ (ii). Now we show (ii) $\implies$ (iii). Let $k$ be the positive recurrent state. Then for all $i$,
	\[
		\nu_k(i) = \mathbb{E}_k\Biggl[\sum_{\ell = 0}^{T_{k} - 1}\mathbbm{1}(X_{\ell} = i) \Biggr]
	.\]
	Since $k$ is recurrent, we have $\nu_k P = \nu_k$, so $\nu_k$ is an invariant measure. Now, remember
	\[
		\sum_{i \in I}\nu_k(i) = \mathbb{E}_k\Biggl[\sum_{\ell = 0}^{T_k - 1} \sum_{i \in I}\mathbbm{1}(X_{\ell} = i) \Biggr] = \mathbb{E}_k[T_k]
	.\]
	Since $k$ is positive recurrent, $\mathbb{E}_k[T_k] < \infty$. So we can define $\pi_i = \nu_k(i)/\mathbb{E}_k[T_k]$, as an invariant distribution.

	Finally, we show (iii) $\implies$ (i). Let $\pi$ be the invariant distribution. Let $k$ be a state, then we want to show $k$ is positive recurrent. First, we show $\pi_k > 0$. Note there exists $i \in I$ such that $\pi_i > 0$. Then since $\pi = \pi P = \pi P^{n}$ for all $n$,
	\[
		\pi_k = \sum_{j} \pi_j P^{n}(j, k)
	.\]
	Take $n$ such that $P^{n}(i, k) > 0$ by irreducibility, then $\pi_k \geq \pi_i P^{n}(i, k) > 0$. Define $\lambda_i = \pi_i/\pi_k$. Then this is an invariant measure on which $\lambda_k = 1$. So since $P$ is irreducible, $\lambda \geq \nu_k$. Hence,
	\[
		\mathbb{E}_k[T_k] = \sum_{i \in I}\nu_k(i) \leq \sum_{i \in I}\lambda_i = \frac{1}{\pi_k} < \infty
	,\]
	giving $k$ positive recurrent.

	Now suppose (i), (ii) and (iii) holds, and let $k$ be a state. We know $k$ is positive recurrent. Define $\lambda_i = \pi_i/\pi_k$, which is an invariant measure with $\lambda_k = 1$. Then $P$ recurrent gives $\lambda = \nu_k$, so from the same calculation as above,
	\[
		\mathbb{E}_k[T_k] = \frac{1}{\pi_k}
	.\]
\end{proofbox}

\begin{corollary}
	If $P$ is irreducible, and $\pi$ is the invariant distribution, then for all $x, y$,
	\[
		\nu_x(y) = \frac{\pi_y}{\pi_x}
	.\]
\end{corollary}

\begin{exbox}
	Take a symmetric simple random walk on $\mathbb{Z}$. Then $P$ is recurrent. Does there exist an invariant distribution? We have
	\[
	\pi_i = \frac{1}{2} \pi_{i-1} + \frac{1}{2} \pi_{i_1}
	.\]
	Then $\pi_i \equiv 1$ is an invariant measure. Since $P$ is recurrent, all invariant measures have to be multiples of $\pi_i \equiv 1$. So there does not exist an invariant distribution, and so this walk in not positive recurrent.

	Take an asymmetric simple random walk on $\mathbb{Z}$, with $P(x, x+1) = p$, $P(x, x-1) = q = 1-p$ with $p > q$. Then  $\pi_i = p \pi_{i-1} + q \pi_{i+1}$ gives
	\[
		\pi_i = a + b \biggl( \frac{p}{q} \biggr)^{i}
	\]
	as an invariant measure for any choice of $a, b$. So, there is no uniqueness up to a multiplicative factor, and indeed, this is valid under the observation that $P$ is transient.

	Again, we can take a simple random walk on $\mathbb{Z}^3$, which is transient. Then $\pi_i \equiv 1$ is an invariant measure, so the existence of an invariant measure does not imply recurrence.

	Now take the asymmetric simple random walk $\mathbb{Z}_{+}$ with $P(x, x+1) = p$, $P(x, x-1) = q$, where $p < q$. We look for invariant measures $\pi = \pi P$. Similar to the walk on $\mathbb{Z}$,
	\[
		\pi_i = \biggl( \frac{p}{q} \biggr)^{i} \pi_0
	\]
	is an invariant measure. Setting $\pi_0 = 1 - p/q$, we can get the invariant distribution
	\[
		\pi_i = \biggl( \frac{p}{q} \biggr)^{i} \biggl(1 - \frac{p}{q} \biggr)
	.\]
	Hence there exists an invariant distribution, so this walk is positive recurrent.
\end{exbox}

\newpage

\section{Time Reversibility}%
\label{sec:time_reversibility}

\begin{proposition}
	Let $P$ be irreducible, and $\pi$ an invariant distribution. Fix $N \in \mathbb{N}$ and $X_0 \sim \pi$. Define $Y_n = X_{N - n}$, for $0 \leq n \leq N$. Then, $(Y_n)$ is a Markov chain with transition matrix
	\[
		\hat P(x, y) = \frac{\pi(y)}{\pi(x)}P(y, x)
	\]
	and invariant distribution $\pi$.
\end{proposition}

\begin{proofbox}
	$\hat P$ is a transition matrix, since
	\[
		\sum_{y} \hat P(x, y) = \sum_{y} \frac{\pi(y)}{\pi(x)} P(y, x) = \frac{\pi(x)}{\pi(x)} = 1.
	\]
	Let $y_0, \ldots, y_n \in I$. Then,
	\begin{align*}
		\mathbb{P}(Y_0 &= y_0, \ldots, Y_n = y_0) = \mathbb{P}(X_n = y_0, \ldots, X_0 = y_N) \\
			       &= \mathbb{P}(X_0 = y_N, \ldots, X_N = y_0) = \pi(y_N)P(y_N, y_{N-1})\cdots P(y_1, y_0) \\
			       &= \pi(y_{N-1})\hat P(y_{N_1}, Y_N) P(y_{N-1}, y_{N_2}) \cdots P(y_1, y_0) \\
			       &= \cdots = \pi(y_0) \hat P(y_0, y_1) \cdots \hat P(y_{N-1}, Y_n).
	\end{align*}
	So $Y$ is $\Mkv(\pi, \hat P)$. Now we check $\hat P$ has invariant distribution $\pi$. Indeed,
	\[
		\sum_{x} \pi(x) \hat P(x, y) = \sum_{x} \pi(x) \frac{\pi(y)}{\pi(x)}P(y, x) = \pi(y)
	.\]
	So $\pi \hat P = \pi$, and $\hat P$ is irreducible. Indeed, let $x, y\in I$. Then as $P$ is irreducible, there exists $x_0 = x, \ldots, x_n = y$ with $P(x_0, x_1) \cdots P(x_{n-1}, x_n) > 0$. So,
	\[
		\hat P(x_n, x_{n-1}) \cdots \hat P(x_1, x_0) = P(x_0, x_1) \cdots P(x_{n-1}, x_n) \frac{\pi(x_0)}{\pi(x_n)} > 0
	.\]
\end{proofbox}

\subsection{Detailed Balance Equation}%
\label{sub:detailed_balance_equation}

\begin{definition}
	A Markov chain with matrix $P$ and invariant distribution $\pi$ is called \textit{(time) reversible}\index{time reversible} if $\hat P = P$, i.e for all $x, y \in I$,
	\[
		\pi(x) P(x, y) = \pi(y) P(y, x)
	,\]
	which is the detailed balance equation\index{detailed balance equation}.

	Equivalently $X$ is reversible of for all $N \in \mathbb{N}$, when $X_0 \sim \pi$, then
	\[
		(X_0, \ldots, X_N) \sim (X_N, \ldots, X_0)
	.\]
\end{definition}

\begin{exbox}
	Take a walk on $\mathbb{Z}_n$, where $P(i, i+1) = \frac{2}{3}$ and $P(i, i-1) = \frac{1}{3}$. Then the invariant distribution is $\pi_i = \frac{1}{n}$, and so $P$ is not reversible, because the
	\[
		\pi(i) P(i, i+1) = \frac{2}{3n} \neq \frac{1}{3n} = \pi(i+1) P(i+1, i)
	,\]
	so the detailed balance equations are not satisfied.

	Now take the same walk, except on $\{0, 1, \ldots, n-1\}$, with $P(0,0) = \frac{1}{3}$ and $P(n-1,n-1) = \frac{2}{3}$. Then $\lambda_i = 2^{i}$ is an invariant distribution, so $\pi(i) \propto 2^{i}$.

	We can then check $\pi$ satisfies the detailed balance equations, so $P$ is time reversible.
\end{exbox}

\begin{lemma}
	Let $\mu$ be a distribution satisfying
	\[
		\mu(x) P(x, y) = \mu(y) P(y, x)
	,\]
	for all $x, y \in I$. Then $\mu$ is an invariant distribution.
\end{lemma}

\begin{proofbox}
	\[
		\sum_{x} \mu(x)P(x, y) = \sum_{x} \mu(y) P(y, x) = \mu(y)
	.\]
	So $\mu = \mu P$.
\end{proofbox}

Thus, when we look for an invariant distribution, we should look for a solution to the detailed balance equations. If a distribution that solves the detailed balance equation exists, then it is an invariant distribution.

On the other hand, if no solution to the detailed balance equation exists, and there is an invariant distribution, then the chain is not reversible.

\begin{exbox}
	Take a simple random walk on a graph $G = (V, E)$, where we stipulate that $G$ is finite and connected. The probabilities are
	\[
		P(x, y) =
		\begin{cases}
			\frac{1}{d(x)} & (x, y) \in E, \\
			0 & \text{else}.
		\end{cases}
	\]
	Since $G$ is connected, $P$ is irreducible. To find an invariant distribution, we look at the detailed balance equation:
	\[
		\pi(x) \frac{1}{d(x)} = \pi(x) P(x, y) = \pi(y) P(y, x) = \pi(y) \frac{1}{d(y)}
	.\]
	Taking $\nu(x) = d(x)$, then $\nu$ is an invariant measure, so
	\[
		\pi(x) = \frac{d(x)}{\sum d(y)} = \frac{d(x)}{2|E|}
	\]
	is an invariant distribution. Hence a simple random walk on $G$ is reversible.
\end{exbox}

\newpage

\section{Convergence to Equilibrium}%
\label{sec:convergence_to_equilibrium}

\begin{theorem}
	Let $I$ be finite, and suppose there is $i \in I$ such that for all $j$,
	\[
		p_{ij}(n) \to \pi(j)
	,\]
	as $n \to \infty$. Then $\pi$ is invariant.
\end{theorem}

Hence, if this holds, then we can show $P$ has an invariant distribution $\pi$. Thus we want to find under what conditions do we have convergence to $\pi$.

\begin{exbox}
	Take a walk on $\{0, 1, \ldots, K\}$. Then, no matter the probabilities, $P^{n}(0, 0) = 0$, hence we cannot find an invariant distribution in this way.
\end{exbox}

\begin{definition}
	Let $P$ be a transition matrix, and let $i \in I$. The period of $i$ is defined as
	\[
		d_i = \gcd \{n \geq 1 \mid P^{n}(i, i) > 0\}
	.\]
	$i$ is called \textit{aperiodic}\index{aperiodic} if $d_i = 1$.
\end{definition}

\begin{lemma}
	Let $P$ be a transition matrix and $i \in I$. Then $d_i = 1$ if and only if $P^{n}(i, i) > 0$ for all $n$ sufficiently large.
\end{lemma}

\begin{proofbox}
	It suffices to show that if $d_1 = 1$, then $P^{n}(i, i) > 0$ for all $n$ large enough. Let $D(i) = \{n \geq 1 \mid P^{n}(1, 1) > 0\}$.

	Observe if $n, m \in D(i)$, then $n + m \in D(i)$. Now it suffices to prove that $D(i)$ contains two consecutive integers: if it contains $m$ and $m+1$, then it will contain $am + b(m+1)$ for all $a, b \in \mathbb{N}$. In particular, this hits all integers greater than $m^2$.

	Let $n, m \in D(i)$ such that $n = m + r$, with $r$ minimal. Then there exists $k = \ell r + s \in D(i)$ with $0 < s < r$. Otherwise, all elements of $D(i)$ would be multiples of $r$.

	Let $a = (\ell + 1)n$, and $b = (\ell + 1)m + k$. Then $a, b \in D(i)$. Notice that $a - b = r - s < r$, contradiction.

	So $r = 1$, and $D(i)$ contains 2 consecutive integers.
\end{proofbox}

\begin{lemma}
	If $P$ is irreducible and $i \in I$ is aperiodic, then all states are aperiodic.
\end{lemma}

\begin{proofbox}
	Let $j \in I$, such that $P^{r}(i, j) > 0$ and $P^{s}(j, i) > 0$. Then for all large $n$,
	\[
		P^{n+r+s}(j,j) \geq P^{s}(j, i) P^{n}(i,i) P^{r}(i,j) > 0
	.\]
	So $j$ is aperiodic.
\end{proofbox}

\subsection{Convergence to Equilibrium Theorem}%
\label{sub:convergence_to_equilibrium_theorem}

\begin{theorem}
	Let $P$ be irreducible and aperiodic with invariant distribution $\pi$. Let $X \sim \Mkv(\lambda, P)$. Then for all $y$,
	\[
		\mathbb{P}(X_n = y) \to \pi(y) \text{ as } n \to \infty
	.\]
	In particular, for all $x$ and $y$,
	\[
		P^{n}(x, y) \to \pi(y) \text{ as } n \to \infty
	,\]
	by taking $\lambda = \delta_x$.
\end{theorem}

\begin{proofbox}
	We couple Markov chains. Let $(Y_n) \sim \Mkv(\pi, P)$, independently of $X$.

	Consider $((X_n, Y_n)) \sim \Mkv(\lambda \pi, \tilde P)$, where
	\[
		\tilde P((x, y), (x', y')) = P(x, x') P(y, y')
	.\]
	Then we claim $\tilde P$ is irreducible. Indeed, $P$ is irreducible, so there exist $\ell, m$ such that
	\[
		P^{\ell}(x, x') >0, \qquad P^{m}(y, y') > 0
	.\]
	Then take $n$ sufficiently large such that $P^{n - \ell}(x', x') > 0$ and $P^{n - m}(y', y') > 0$ (by aperiodicity). Then
	\[
		\tilde P^{n}((x, y), (x', y')) = P^{n}(x, x') P^{n}(y, y') > 0
	,\]
	for all $n$ large enough.

	Notice that $\tilde P$ has invariant distribution $\tilde \pi(x, y) = \pi(x) \pi(y)$. Hence $\tilde P$ is positive recurrent. For $a \in I$, we can define
	\[
		T = \inf\{n \geq 1 \mid (X_n, Y_n) = (a, a)\}
	.\]
	Then $T$ is a stopping time, and since $\tilde P$ is positive recurrent, $\mathbb{P}(T < \infty) = 1$. Now define
	\[
	Z_n =
	\begin{cases}
		X_n & n < T, \\
		Y_n & n \geq T
	\end{cases}
	.\]
	(This is the coupled Markov chain). Then we claim $Z \sim \Mkv(\lambda, P)$. Indeed, $\mathbb{P}(Z_0 = x) = \mathbb{P}(X_0 = x) = \lambda(x)$, since $T \neq 0$, and if we let $A = \{Z_{n+1} = z_{n+1}, \ldots, Z_0 = z_0\}$, then we can write
	\begin{align*}
		\mathbb{P}(Z_{n+1} &= y \mid Z_n = x, A) = \mathbb{P}(Z_{n+1} = y, T > n \mid Z_n = x, A) \\
				   &+ \mathbb{P}(Z_{n+1} = y, T \leq n \mid Z_n = x, A).
	\end{align*}
	Now notice that
	\begin{align*}
		\mathbb{P}(Z_{n+1} &= y, T > n \mid Z_n = x, A) \\
				   &= \mathbb{P}(X_{n+1} = y \mid T > n, X_n = x, A) \mathbb{P}(T > n \mid Z_n = x, A) \\
				   &= P(x, y) \mathbb{P}(T > n \mid Z_n = x, A),
	\end{align*}
	by the Strong Markov property. Similarly, we can compute
	\begin{align*}
		\mathbb{P}(Z_{n+1} &= y , T \leq n \mid Z_n = x, A) \\
				   &= P(x, y) \mathbb{P}(T \leq n, Z_n = x, A).
	\end{align*}
	Adding these up, we get
	\[
		\mathbb{P}(Z_{n+1} = y \mid Z_n = x, A) = P(x, y)
	,\]
	so $(Z_n) \sim (X_n)$. Now we want to show that $|\mathbb{P}(X_n = y) - \pi(y)| \to 0$ as $n \to \infty$.

	But $Y$ is stationary, so $\mathbb{P}(Y_n = y) = \pi(y)$, and
	\begin{align*}
		|\mathbb{P}(X_n &= y) - \mathbb{P}(Y_n = y)| = |\mathbb{P}(Z_n = y) - \mathbb{P}(Y_n = y)| \\
				&= |\mathbb{P}(Z_n = y, n < T) + \mathbb{P}(Z_n = y, n \geq T) - \mathbb{P}(Y_n = y)| \\
				&= |\mathbb{P}(X_n = y, n < T) + \mathbb{P}(Y_n = y, n \geq T) - \mathbb{P}(Y_n = y)| \\
				&= |\mathbb{P}(X_n = y, n < T) - \mathbb{P}(Y_n = y, n < T)| \leq \mathbb{P}(T > n).
	\end{align*}
	By taking $n \to \infty$, we get $\mathbb{P}(T > n) \to 0$, as $\mathbb{P}(T < \infty) = 1$. This gives the required result.
\end{proofbox}

\begin{theorem}
	Let $P$ be irreducible and aperiodic. Suppose $P$ is null-recurrent. Then for all $x, y$,
	\[
		P^{n}(x, y) \to 0 \text{ as } n \to \infty
	.\]
\end{theorem}

\begin{proofbox}
	Again, consider $\tilde(P(x, y), (x', y')) = P(x, x') P(y, y')$. Then we have shown $\tilde P$ is irreducible.

	We will further show that $\tilde P$ is transient. Indeed,
	\[
		\sum_{n} \tilde P^{n}((x, x), (y, y)) = \sum_{n} (P^{n}(x, y))^2 < \infty
	.\]
	Moreover $\tilde P$ is recurrent, as before. Now, since $P$ is recurrent,
	\[
		\nu_y(z) = \mathbb{E}_y\Biggl[\sum_{i = 1}^{T_y - 1} \mathbbm{1}(X_i = z) \Biggr]
	\]
	is an invariant measure. But as $P$ is null-recurrent, $\mathbb{E}_y[T_y] = \infty$, so $\nu_y(I) = \infty$.

	Fix $M \in \mathbb{N}$. Since $\nu_y(I) = \infty$, we can find a finite set $A$ such that $\nu_y(A) > M$. Define
	\[
		\mu(x) = \frac{\nu_y(x)}{\nu_y(A)} \mathbbm{1}(x \in A)
	.\]
	This is a probability measure which satisfies
	\[
		\mu P^{n}(z) = \sum_{x} \mu(x) P^{n}(x, z) \leq \sum_{x} \frac{\nu_y(x)}{\nu_y(A)} P^{n}(x, z) = \frac{\nu_y(z)}{\nu_y(A)}
	.\]
	Consider $(X, Y) \sim \mu \times \delta_x$ under $\tilde P$, and $T = \inf\{n \geq 0 \mid (X_n, Y_n) = (x, x)\}$.

	Since $\tilde P$ is recurrent, $\mathbb{P}(T < \infty) = 1$, so again we define
	\[
	Z_n =
	\begin{cases}
		X_n & n < T, \\
		Y_n & n \geq T.
	\end{cases}
	\]
	Then $Z_n \sim \Mkv(\mu, P)$, similar to before. We can then see that
	\[
		\mathbb{P}(Z_n = y) = \mu P^{n}(y) \leq \frac{\nu_y(y)}{\nu_y(A)} = \frac{1}{\nu_y(A)} < \frac{1}{M}
	.\]
	Therefore, we can bound
	\begin{align*}
		P^{n}(x, y) &= \mathbb{P}(Y_n = y) = \mathbb{P}(Y_n = y, n < T) + \mathbb{P}(Y_n = y, n \geq T) \\
			    &\leq \mathbb{P}(T > n) + \mathbb{P}(Z_n = y) < \mathbb{P}(T > n) + \frac{1}{M}
	\end{align*}
	Taking $n \to \infty, \mathbb{P}(T > n) \to 0$, so $\lim P^{n}(x, y) < 1/M$. Then taking $M \to 0$, we get the desired result.
\end{proofbox}

\newpage

\subsection{Ergodic Theorem}%
\label{sub:ergodic_theorem}

\begin{theorem}\index{ergodic theorem}
	Let $P$ be irreducible with an invariant distribution $\pi$. Suppose $X_0 \sim \lambda$. Then with probability $1$, we have, for all $x \in I$,
	\[
		\lim_{n \to \infty} \frac{\sum_{i = 0}^{n-1} \mathbbm{1}(X_i = x)}{n} \to \pi(x)
	.\]
\end{theorem}

\begin{proofbox}
	Since $P$ has an invariant distribution, it is recurrent and so $T_x < \infty$.

	By the strong Markov property, $(X_{T_x + n}) \sim \Mkv(\delta_x, P)$, independent of $X_0, \ldots, X_{T_x}$. Since the limit is not affected by changing the initial distribution, it suffices to consider $\lambda = \delta_x$.

	Write $\nu_n(x) = \sum_{i = 0}^{n-1} \mathbbm{1}(X_i = x)$, the number of visits to $x$ by time $n-1$, and define the successive return times to $x$ by $T_x^{(0)} = 0$, and
	\[
		T_x^{(k+1)} = \inf\{t \geq T_x^{(k)} + 1 \mid X_t = x\}
	.\]
	Now, these are stopping times. Define
	\[
		S_x^{(k)} =
		\begin{cases}
			T_x^{(k)} - T_x^{(k-1)} & \text{if } T_x^{(k-1)} < \infty, \\
			0 & \text{otherwise}.
		\end{cases}
	\]
	By the strong Markov property, $(S_x^{(k)})$ are iid and have expectation
	\[
		\mathbb{E}[S_x^{(1)}] = \mathbb{E}_x[T_x] = \frac{1}{\pi(x)}
	.\]
	By definition, we have $T_x^{(\nu_n(x) - 1)} \leq n-1$, and $T_x^{(\nu_n(x))} \geq n$. Using these two inequalities,
	\begin{align*}
		S_x^{(1)} + \cdots + S_x^{(\nu_n(x) - 1)} &\leq n-1, \\
		S_x^{(1)} + \cdots + S_x^{(\nu_n(x))} &\geq n, \\
		\implies S_x^{(1)} + \cdots + S_x^{(\nu_n(x) - 1)} < n \leq &S_x^{(1)} + \cdots + S_x^{(\nu_n(x))}. \tag{$\ast$}
	\end{align*}
	Since $(S_x^{(k)})$ are iid and have finite expectation, by the strong law of large numbers,
	\[
		\frac{S_x^{(1)} + \cdots + S_x^{(k)}}{k} \to \mathbb{E}[S_x^{(1)}]
	,\]
	with probability 1. By recurrence, $\nu_n(x) \to \infty$ as $n \to \infty$. So, dividing through $(\ast)$ by $(\nu_n(x))$, both the left hand side and right hand side converge to $\mathbb{E}[S_x^{(1)}] = \frac{1}{\pi(x)}$, and hence
	\[
		\lim_{n \to \infty} \frac{n}{\nu_n(x)} \to \frac{1}{\pi(x)}, \implies \lim_{n \to \infty} \frac{\nu_n(x)}{n} = \pi(x)
	.\]
\end{proofbox}

\newpage

\section{Continuous Time Markov Chains}%
\label{sec:continuous_time_markov_chains}

We look at Markov chains $(X_t)$, for $t \in \mathbb{R}_{+}$. Let $S_x$ be the holding time at the state $x$. Then, using the Markov property,
\begin{align*}
	\mathbb{P}(S_x &> t + s \mid S_x > s) = \mathbb{P}(X_u = x \;\forall u \in [0, t+s] \mid X_u = x \; \forall u \in [o, s]) \\
		       &= \mathbb{P}(X_u = x \; \forall u \in [s, t+s] \mid X_u = x \; \forall u \in [0, s]) \\
		       &=\mathbb{P}(X_u = x \; \forall u \in [s, t+s] \mid X_s = x) \\
		       &= \mathbb{P}_x(X_u = x \; \forall u \in [0, t]) = \mathbb{P}(S_x > t).
\end{align*}

So $S_x$ has the probability $\mathbb{P}(S_x > t + s \mid S_x > s) = \mathbb{P}(S_x > t)$, for all $s, t$. So $S_x$ has the memoryless property, which implies $S$ has the exponential distribution with some parameter.

Hence we can think of a continuous time Markov chain as a discrete Markov chain, with exponential holding time.

\subsection{Poisson process}%
\label{sub:poisson_process}\index{Poisson process}

Suppose $S_1, S_2, \ldots$ are iid with distribution $\mathrm{Exp}(\lambda)$. Then, let $J_i = \sum_{j = 1}^{i} S_j$. We can then define
\[
	X_t = i \text{ if } J_i \leq t < J_{i+1}
.\]
We can think of the Poisson process as $X = (J_i)_{i}$.

Then, in any interval, the number of arrivals follows a Poisson distribution, hence the name.

\newpage

\printindex

\end{document}
