\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[a4paper]{geometry}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{adjustbox}
\usepackage[shortlabels]{enumitem}
\usepackage{parskip}
\makeatletter
\newcommand{\@minipagerestore}{\setlength{\parskip}{\medskipamount}}
\makeatother
\usepackage{imakeidx}

\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{null}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\Orb}{Orb}
\DeclareMathOperator{\Stab}{Stab}
\DeclareMathOperator{\ccl}{ccl}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Syl}{Syl}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Fit}{Fit}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\epi}{epi}


\newcommand{\incfig}[1]{%
	\def\svgwidth{\columnwidth}
	\import{./figures/}{#1.pdf_tex}
}

\setlength\parindent{0pt}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\pagestyle{fancy}
\fancyhf{}
\rhead{\leftmark}
\lhead{Page \thepage}
\setlength{\headheight}{15pt}

\makeindex[intoc]

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newcommand{\mapsfrom}{\mathrel{\reflectbox{\ensuremath{\mapsto}}}}

\begin{document}

\hypersetup{pageanchor=false}
\begin{titlepage}
	\begin{center}
		\vspace*{1em}
		\Huge
		\textbf{IB Linear Algebra}

		\vspace{1em}
		\large
		Ishan Nath, Michaelmas 2022

		\vspace{1.5em}

		\Large

		Based on Lectures by Prof. Pierre Raphael

		\vspace{1em}

		\large
		\today
	\end{center}
	
\end{titlepage}
\hypersetup{pageanchor=true}

\tableofcontents

\newpage

\section{Vector Spaces and Subspaces}%
\label{sec:vector_spaces_and_subspaces}

Let $F$ be an arbitrary field.

\begin{definition}[$F$ vector space]\index{vector space}
	A $F$ vector space is an abelian group $(V, +)$ equipped with a function
	\begin{align*}
		F \times V &\to V \\
		(\lambda, v) &\mapsto \lambda v
	\end{align*}
	such that
	\begin{itemize}
		\item $\lambda(v_1 + v_2) = \lambda v_1 + \lambda v_2$, 
		\item $(\lambda_1 + \lambda_2)v = \lambda_1 v + \lambda_2 v$,
		\item $\lambda(\mu v) = (\lambda \mu) v$,
		\item $1 \cdot v = v$.
	\end{itemize}
\end{definition}
We know how to
\begin{itemize}
	\item Sum two vectors
	\item Multiply a vector $v \in V$ by a scalar $\lambda \in F$.
\end{itemize}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	\begin{enumerate}[(i)]
		\item[]
		\item Take $n \in \mathbb{N}$, then $F^{n}$ is the set of column vectors of length $n$ with elements in $F$. We have
			\[
			v \in F^{n}, v =
			\begin{pmatrix}
				x_1 \\
				\vdots \\
				x_n
			\end{pmatrix}
			, x_i \in F
			,\]
			\[
			v + w =
			\begin{pmatrix}
				v_1 \\
				\vdots \\
				v_n
			\end{pmatrix}
			+
			\begin{pmatrix}
				w_1 \\
				\vdots \\
				w_n
			\end{pmatrix}
			=
			\begin{pmatrix}
				v_1 + w_1 \\
				\vdots \\
				v_n + w_n
			\end{pmatrix}
			,\]
			\[
			\lambda v =
			\begin{pmatrix}
				\lambda v_1 \\
				\vdots \\
				\lambda v_n
			\end{pmatrix}
			.\]
			Then $F^{n}$ is a $F$ vector space.
	\end{enumerate}
	
\end{example}

\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\begin{enumerate}[(i)]
		\setcounter{enumi}{1}
		\item For any set $X$, take
			\[
				\mathbb{R}^{X} = \{f : X \to \mathbb{R}\}
			.\]
			Then $\mathbb{R}^{X}$ is an $\mathbb{R}$ vector space.
		\item Take $M_{n, m}(F)$, the set of $n \times m$ $F$ valued matrices. Then $M_{n, m}(F)$ is a $F$ vector space.
\end{enumerate}

\end{adjustbox}

\begin{remark}
	The axiom of scalar multiplication implies that for all $v \in V$, $0 \cdot v = \mathbf{0}$.
\end{remark}

\begin{definition}[Subspace]\index{subspace}
	Let $V$ be a vector space over $F$. A subset $U$ of $V$ is a vector subspace of $V$ (denoted $U \leq V$) if
	\begin{itemize}
		\item $0 \in U$,
		\item $(u_1, u_2) \in U \times U$ implies $u_1 + u_2 \in U$,
		\item $(\lambda, u) \in F \times U$ implies $\lambda u \in U$.
	\end{itemize}
\end{definition}
Note if $V$ is an $F$ vector space, and $U \leq V$, then $U$ is an $F$ vector space.

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	\begin{enumerate}[(i)]
		\item[]
		\item Take $V = \mathbb{R}^{\mathbb{R}}$, the space of functions $f : \mathbb{R} \to \mathbb{R}$. Let $\mathcal{C}(\mathbb{R})$ be the space of continuous function $f : \mathbb{R} \to \mathbb{R}$. Then $\mathcal{C}(\mathbb{R}) \leq \mathbb{R}^{\mathbb{R}}$.
		\item Take the elements of $\mathbb{R}^3$ which sum up to $t$. This is a subspace if and only if $t = 0$.
	\end{enumerate}	
\end{example}

\end{adjustbox}

Note that the union of two subspaces is generally not a subspace, as it is usually not closed under addition.

\begin{proposition}
	Let $V$ be an $F$ vector space, and $U, W \leq V$. Then $U \cap W \leq V$.
\end{proposition}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} Since $0 \in U, 0 \in W$, $0 \in U \cap W$. Now consider $(\lambda, \mu) \in F^2$, and $(v_1, v_2) \in (U \cap W)^2$. Take $\lambda_1 v_1 + \lambda_2 v_2$. Since $u_1,v_1 \in U$, this is in $U$. Similarly, it is in $W$. So it is in $U \cap W$, and $U \cap W \leq V$.
\end{adjustbox}

\begin{definition}[Sum of subspaces]\index{subspace sum}
	Let $V$ be an $F$ vector space. Let $U, W \leq V$. Then the \textbf{sum} of $U$ and $W$ is the set
	\[
		U + W = \left\{ u + w \mid (u, w) \in U \times W \right\}
	.\]
\end{definition}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:} Note $0 = 0 + 0 \in U + W$. Take $\lambda_1 f + \lambda_2 g$, where $f, g \in U + W$. Then we can write $f = f_1 + f_2, g = g_1 + g_2$, where $f_1, g_1 \in U$, $f_2, g_2 \in W$. Then 
\[
	\lambda_1 f + \lambda_2 g = \lambda_1 (f_1 + f_2) + \lambda_2(g_1 + g_2) = (\lambda_1 f_1 + \lambda_2 g_1) + (\lambda_1 f_2 + \lambda_2 g_2) \in U + W
.\]
\end{adjustbox}

\begin{remark}
	$U + W$ is the smallest subspace of $V$ which contains both $U$ and $W$.
\end{remark}

\subsection{Subspaces and Quotients}%
\label{sub:subspaces_and_quotients}

\begin{definition}[Quotient]\index{quotient}
	Let $V$ be an $F$ vector space. Let $U \leq V$. The quotient space $V / U$ is the abelian group $V/U$ equipped with the scalar product multiplication
	\begin{align*}
		F \times V/U &\to V/U \\
		(\lambda, v + U) &\mapsto \lambda v + U
	\end{align*}
\end{definition}

\begin{proposition}
	$V/U$ is an $F$ vector space.
\end{proposition}

\newpage

\section{Spans, Linear Independence and the Steinitz Exchange Lemma}%
\sectionmark{Spans, LI and the SEL}
\label{sec:spans_linear_independence_and_the_steinitz_exchange_lemma}

\begin{definition}[Span of a family of vectors]\index{span}
	Let $V$ be a $F$ vector space. Let $S \subset B$ be a subset. We define
	\begin{align*}
		\langle S \rangle &= \left\{ \text{finite linear combinations of elements of } S \right\} \\
				  &= \left\{ \sum_{\delta \in J} \lambda_{\delta} v_{\delta},  v_{\delta} \in S,  \lambda_{\delta} \in F, J \text{ finite} \right\}.
	\end{align*}
\end{definition}

By convention, we let $\langle \emptyset \rangle = \{0\}$.

\begin{remark}
	$\langle S' \rangle$ is the smallest vector subspace which contains $S$.
\end{remark}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Take $V = \mathbb{R}^3$, and
	\[
	S = \left\{
		\begin{pmatrix}
			1 \\
			0 \\
			0
		\end{pmatrix}
		,
		\begin{pmatrix}
			0 \\
			1\\
			2
		\end{pmatrix}
		,
		\begin{pmatrix}
			3 \\
			-2 \\
			4
		\end{pmatrix}
	\right\}
	.\]
	Then we have
	\[
		\langle S' \rangle = \left\{
			\begin{pmatrix}
				a \\
				b \\
				2b
			\end{pmatrix}
			,
		(a, b) \in \mathbb{R}^2\right\}
	.\]
	Take $V = \mathbb{R}^{n}$, and let $e_i$ be the $i$'th basis vector. Then $V = \langle e_1, \ldots, e_n \rangle$.

	Take $X$ a set, and $V = \mathbb{R}^{X}$. Let $S_x : X \to \mathbb{R}$, such that $y \mapsto 1$ if $x = y$, otherwise $y \mapsto 0$. Then
	\begin{align*}
		\langle (S_x)_{x \in X} \rangle &= \{f \in \mathbb{R}^{X} \mid f \text{ has finite support}\}.
	\end{align*}
\end{example}

\end{adjustbox}

\begin{definition}
	Let $V$ be a $F$ vector space. Let $S'$ be a subset of $V$. We may say that $S$ \textbf{spans} $V$ if $\langle S \rangle = V$.
\end{definition}

\begin{definition}[Finite dimension]\index{finite dimension}
	Let $V$ be a $F$ vector space. We say that $V$ is \textbf{finite dimensional} if it is spanned by a finite set.
\end{definition}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	Consider $P[x]$, the polynomials over $\mathbb{R}$, and $P_n[x]$, the polynomials over $\mathbb{R}$ with degree $\leq n$. Then since
	\[
		\langle 1, x, \ldots, x^{n}\rangle = P_n[x]
	,\]
	$P_n[x]$ is finite dimensional, however $P[x]$ is not.
\end{example}

\end{adjustbox}

\begin{definition}[Independence]\index{linear independence}
	We say that $(v_1, \ldots, v_n)$, elements of $V$ are \textbf{linearly independent} if
	\[
	\sum_{i = 1}^{n} \lambda_i v_i = 0 \implies \lambda_i = 0 \, \forall i
	.\]
\end{definition}

\begin{remark}
	\begin{enumerate}[1.]
		\item[]
		\item We also say that the family $(v_1, \ldots, v_n)$ is \textbf{free}.
		\item Equivalently, $(v_1, \ldots, v_n)$ are not linearly independent if one of these vectors is a linear combination of the remaining $(n-1)$.
		\item If $(v_i)$ is free, then $v_i = 0$ for all $i$.
	\end{enumerate}
	
\end{remark}

\begin{definition}[Basis]\index{basis}
	A subset $S$ of $V$ is a \textbf{basis} of $V$ if and only if
	\begin{enumerate}[(i)]
		\item $\langle S' \rangle = V$,
		\item $S$ is linearly independent.
	\end{enumerate}
	
\end{definition}

\begin{remark}
	A subset $S$ that generates $V$ is a generating family, so a basis $S$ is a free generating family.
\end{remark}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\begin{example}
	For $V = \mathbb{R}^{n}$, then $(e_i)$ is a basis of $V$.

	If $V = \mathbb{C}$, then for $F = \mathbb{C}$, $\{1\}$ is a basis.

	If $V = P[x]$, then $S = \{x^{n}, n \geq 0\}$ is a basis for $V$.
\end{example}

\end{adjustbox}

\begin{lemma}
	$V$ is a $F$ vector space. Then $(v_1, \ldots, v_n)$ is a basis of $V$ if and only if any vector $v \in V$ has a unique decomposition
	\[
	v = \sum_{i = 1}^{n} \lambda_i v_i
	.\]
\end{lemma}

\begin{remark}
	We call $(\lambda_1, \ldots, \lambda_n)$ the coordinates of $v$ in the basis $(v_1, \ldots, v_n)$.
\end{remark}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} Since $\langle v_1, \ldots, v_n \rangle = V$, we must have 
	\[
	v = \sum_{i = 1}^{n} \lambda_i v_i
	\]
	for some $\lambda_i$. Now assume
	\begin{align*}
		v = \sum_{i = 1}^{n}\lambda_i v_i = \sum_{i = 1}^{n}\lambda_i' v_i, \\
		\implies \sum_{i = 1}^{n}(\lambda_i - \lambda_i') v_i = 0.
	\end{align*}
	Since $v_i$ are free, $\lambda_i = \lambda_i'$.
\end{adjustbox}

\begin{lemma}
	If $(v_1, \ldots, v_n)$ spans $V$, then some subset of this family is a basis of $V$.
\end{lemma}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} If $(v_1, \ldots, v_n)$ are linearly independent, we are done. Otherwise assume they are not independent, then by possibly reordering the vectors, we have
	\[
		v_n \in \langle v_1, \ldots, v_{n-1}\rangle
	.\]
	Then we have $V = \langle v_1, \ldots, v_n \rangle = \langle v_1, \ldots, v_{n-1}\rangle$.
	By iterating, we must eventually get to an independent set.
\end{adjustbox}

\begin{theorem}[Steinitz Exchange Lemma]\index{Steinitz exchange lemma}
	Let $V$ be a finite dimensional vector space over $F$. Take
	\begin{enumerate}[\normalfont(i)]
		\item $(v_1, \ldots, v_m)$ free,
		\item $(w_1, \ldots, w_n)$ generating.
	\end{enumerate}
	Then $m \leq n$, and up to reordering, $(v_1, \ldots, v_m, w_{m+1}, \ldots, w_n)$ spans $V$.
\end{theorem}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\textbf{Proof:} Induction. Suppose that we have replaced $l$ of the $w_i$, reordering if necessary, so
\[
	\langle v_1, \ldots, v_{l}, w_{l+1}, \ldots, w_n \rangle = V
.\]
If $m = l$, we are done. Otherwise, $l < m$. Then since these vectors span $V$, we have

 
\end{adjustbox}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
\[
v_{l+1} = \sum_{i \leq l}a_i v_i + \sum_{i > l}\beta_i w_i
.\]
	Since $(v_1, \ldots, v_{l+1})$ is free, some of the $\beta_i$ are non-zero. Upon reordering, we may let $\beta_{l+1} \neq 0$. Then,
\[
	w_{l+1} = \frac{1}{\beta_{l+1}} \left[ v_{l+1} - \sum_{i \leq l}\alpha_i v_i - \sum_{i > l+1} \beta_i w_i \right]
.\]
Hence, $V = \langle v_1, \ldots, v_l, w_{l+1}, \ldots, w_n \rangle = \langle v_1, \ldots, v_l, v_{l+1}, w_{l+1}, \ldots, w_n \rangle = \langle v_1, \ldots, v_{l+1}, w_{l+2}, \ldots, w_n \rangle$. Iterating this process, we eventually get $l = m$, which then proves $m \leq n$.
\end{adjustbox}

\newpage

\section{Basis, Dimension and Direct Sums}%
\label{sec:basis_dimension_and_direct_sums}

\begin{corollary}
	Let $V$ be a finite dimensional vector space over $F$. Then any two bases of $V$ have the same number of vectors, called the \textbf{dimension}\index{dimension} of $V$.
\end{corollary}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} take $(v_1, \ldots, v_n), (w_1, \ldots, w_m)$ bases of $V$.
	\begin{enumerate}[(i)]
		\item As $(v_i)$ is free and $(w_i)$ is generating, $n \leq m$.
		\item As $(w_i)$ is free and $(v_i)$ is generating, $m \leq n.$
	\end{enumerate}
	So $m = n$.
\end{adjustbox}

\begin{corollary}
	Let $V$ be a vector space over $F$ with dimension $n \in \mathbb{N}$.
	\begin{enumerate}[\normalfont(i)]
		\item Any set of independent vectors has at most $n$ elements, with equality if and only if it is a basis.
		\item Any spanning set of vectors has at least $n$ elements, with equality if and only if it is a basis.
	\end{enumerate}
	
\end{corollary}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} Exercise (fill this in).
\end{adjustbox}

\begin{proposition}
	Let $U, W$ be finite dimensional subspaces of $V$. If $U$ and $W$ are finite dimensional, then so is $U + W$, and
	\[
		\dim (U + W) = \dim U + \dim W - \dim(U \cap W)
	.\]
\end{proposition}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} Pick $(v_1, \ldots, v_l)$ a basis of $U \cap W$. Extend to a basis $(v_1, \ldots, v_l, u_1, \ldots, u_m)$ of $U$, and a basis $(v_1, \ldots, v_l, w_1, \ldots, w_n)$ of $W$. Then we show $(v_1, \ldots, v_l, u_1, \ldots, u_m, w_1, \ldots, w_n)$ is a basis of $U + W$.

	It is clearly a generating family, so we will show it is free. Suppose
	\[
		\sum_{i = 1}^{l} \alpha_i v_i + \sum_{ = 1}^{m} \beta_i u_i + \sum_{i = 1}^{n} \gamma_i w_i = 0
	.\]
	Then we get
	\[
	\sum_{i = 1}^{n} \gamma_i w_i \in U \cap W
	,\]
	implying that
	\[
	\sum_{i = 1}^{l} s_i v_i = \sum_{i = 1}^{n} \gamma_i w_i
	.\]
	But since $(v_1, \ldots, w_n)$ is a basis of $W$, we get $\gamma_i = 0$. Similarly, $\beta_i = 0$. Thus,
	\[
	\sum_{i = 1}^{l} \alpha_i v_i = 0
	.\]
	Since $(v_i)$ is a basis of $U \cap W$, $\alpha_i = 0$.
\end{adjustbox}

\begin{proposition}
	Let $V$ be a finite dimensional vector space over $F$. Let $U \leq V$. Then $U$ and $V/U$ are both finite dimensional and
	\[
		\dim V = \dim U + \dim(V/U)
	.\]
\end{proposition}

\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} Let $(u_1, \ldots, u_l)$ be a basis of $U$. Extend to a basis $(u_1, \ldots, u_l, w_{l+1}, \ldots, w_{n})$ of $V$. Then we show that $(w_{l+1} + U, \ldots, w_{n} + U)$ is a basis of $V/U$. (Fill this in).
\end{adjustbox}

\begin{remark}
	If $U \leq V$, then we say $U$ is proper if $U \neq V$. Then for finite dimensions, $U$ proper\index{proper subspace} implies $\dim U < \dim V$, as $\dim(V/U) > 0$.
\end{remark}

\begin{definition}[Direct sum]\index{direct sum}
	Let $V$ be a vector space over $F$, and $U, W \leq V$. We say $V = U \oplus W$ if and only if any element of $v \in V$ can be uniquely decomposed as $v = u + w$ for $u \in U, w \in W$.
\end{definition}

\begin{remark}
	If $V = U \oplus W$, we say that $W$ is a complement\index{complement} of $U$ in $V$. There is no uniqueness of such a complement.
\end{remark}

In the sequel, we use the following notation. Let $\mathcal{B}_1 = \{u_1, \ldots, u_l\}$ and $\mathcal{B}_2 = \{w_1, \ldots, w_m\}$ be collections of vectors. Then
\[
	\mathcal{B}_1 \cup \mathcal{B}_2 = \{u_1, \ldots, u_l, w_1, \ldots, w_m\}
\]
with the convention that $\{v\} \cup \{v\} = \{v, v\}$.

\begin{lemma}
	Let $U, W \leq V$. Then the following are equivalent:
	\begin{enumerate}[\normalfont(i)]
		\item $V = U \oplus W$;
		\item $V = U + W$ and $U \cap W = \{0\}$;
		\item For any basis $\mathcal{B}_1$ of $U$, $\mathcal{B}_2$ of $W$, the union $\mathcal{B} = \mathcal{B}_1 \cup \mathcal{B}_2$ is a basis of $V$.
	\end{enumerate}
\end{lemma}


\begin{adjustbox}{minipage = \columnwidth - 25.5pt, margin=1em, frame=1pt, margin=0em}
	\textbf{Proof:} We show (ii) implies (i). Let $V = U + W$, then clearly $U, W$ generate $V$. We only need to show uniqueness. Suppose $u_1 + w_1 = u_2 + w_2$. Then
	\[
		u_1 - u_2 = w_2 - w_1 \in U \cap W = \{0\}
	.\]
	Hence $u_1 = u_2$ and $w_1 = w_2$, as required.

	Now we show (i) implies (iii). Let $\mathcal{B}_1$ be a basis of $U$, and $\mathcal{B}_2$ a basis of $W$. Then $\mathcal{B} = \mathcal{B}_1 \cup \mathcal{B}_2$ generates $U + W = V$, and $\mathcal{B}$ is free, as if $\sum \lambda_i v_i = u + w = 0$, then $0 = 0 + 0$ uniquely, so $u = 0, w = 0$, giving $\lambda_i = 0$ for all $i$.

	Finally, we show (iii) implies (ii). Let $\mathcal{B} = \mathcal{B}_1 \cup \mathcal{B}_2$. Then since $\mathcal{B}$ is a basis of $V$,
	\[
	v = \sum_{u_i \in \mathcal{B}_1}\lambda_i u_i + \sum_{w_i \in \mathcal{B}_2}\lambda_i w_i = u + w
	.\]
	Now if $v \in U \cap W$,
	\[
	v = \sum_{u \in \mathcal{B}_1} \lambda_u u = \sum_{w \in \mathcal{B}_2} \lambda_w w
	.\]
	This gives
	\[
	\sum_{u \in \mathcal{B}_1}\lambda_u u - \sum_{w \in \mathcal{B}_2} \lambda_w w = 0
	.\]
	Since $\mathcal{B}_1 \cup \mathcal{B}_2$ is free, we get $\lambda_u = \lambda_w = 0$, so $U \cap W = \{0\}$.
\end{adjustbox}


\newpage

\printindex

\end{document}
